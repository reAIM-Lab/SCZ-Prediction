{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "import sys\n",
    "import gc\n",
    "import pymssql\n",
    "import pickle \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = \"connection to SQL server\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fe65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccae_validation_set = False\n",
    "path = 'PATH'\n",
    "raw_path = path + 'RAW_DATA_PATH'\n",
    "int_path = path + 'INTERMEDIATE_PATH'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be3102",
   "metadata": {},
   "source": [
    "# Create Data\n",
    "1. Read in data\n",
    "2. Create a population dataframe with N (N = len_seq) entries per patient. This should have the start date (inclusive) and end date (exclusive) for each \"iteration\" \n",
    "3. In a loop: \n",
    "- Limit data to that date-range for each person\n",
    "- Run a modified version of the function used by the XGBoost model to generate features. \n",
    "- Divide by the number of years in the time chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7fab9b",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Also constrict to patients with psychosis at least 90 days pre-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db507ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days_prediction = 90\n",
    "df_pop = pd.read_csv(raw_path+'population.csv')\n",
    "df_pop.rename({'psychosis_dx_date':'psychosis_diagnosis_date'}, axis=1, inplace=True)\n",
    "df_pop['psychosis_diagnosis_date'] = pd.to_datetime(df_pop['psychosis_diagnosis_date'], format=\"mixed\", dayfirst=False)\n",
    "df_pop['cohort_start_date'] = pd.to_datetime(df_pop['cohort_start_date'], format=\"mixed\", dayfirst=False)\n",
    "df_pop = df_pop.loc[(df_pop['cohort_start_date']-df_pop['psychosis_diagnosis_date']).dt.days >= num_days_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visits = pd.read_csv(raw_path+'temporal_visits.csv')\n",
    "df_pop = df_pop.merge(all_visits.groupby('person_id').min()['visit_start_date'], how='left', left_on='person_id',right_index=True)\n",
    "df_pop.rename({'visit_start_date':'first_visit'}, axis=1, inplace=True)\n",
    "df_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conds = pd.read_csv(raw_path+'temporal_conditions.csv')\n",
    "all_meds = pd.read_csv(raw_path+'temporal_medications.csv')\n",
    "all_procedures = pd.read_csv(raw_path+'temporal_procedures.csv')\n",
    "all_labs = pd.read_csv(raw_path+'temporal_labs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ddc75",
   "metadata": {},
   "source": [
    "### Restrict all data to appropriate time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meds = all_meds.loc[all_meds['person_id'].isin(df_pop['person_id'])]\n",
    "all_meds['cohort_start_date'] = pd.to_datetime(all_meds['cohort_start_date'], format=\"mixed\", dayfirst=False)\n",
    "all_meds['drug_era_start_date'] = pd.to_datetime(all_meds['drug_era_start_date'], format=\"mixed\", dayfirst=False)\n",
    "all_meds['drug_era_end_date'] = pd.to_datetime(all_meds['drug_era_end_date'], format=\"mixed\", dayfirst=False)\n",
    "all_meds = all_meds.loc[(all_meds['cohort_start_date']-all_meds['drug_era_end_date']).dt.days >= num_days_prediction]\n",
    "all_meds['days_to_cohort_start'] = (all_meds['cohort_start_date']-all_meds['drug_era_start_date']).dt.days\n",
    "\n",
    "# medications mapping \n",
    "medications_mapping_query = (\"SELECT c_atc.concept_id as rolled_concept_id, c_atc.concept_name as rolled_concept_name, c_standard.concept_id as descendant_concept_id, c_standard.concept_name as descendant_concept_name \"+\n",
    "                             \"FROM dbo.concept as c_atc \"+\n",
    "                             \"LEFT JOIN dbo.concept_ancestor as ca on ancestor_concept_id=c_atc.concept_id \"+\n",
    "                             \"LEFT JOIN dbo.concept as c_standard on c_standard.concept_id = descendant_concept_id \"+\n",
    "                             \"WHERE c_atc.concept_class_id = 'ATC 3rd' AND c_standard.standard_concept = 'S'\")\n",
    "\n",
    "medications_mapping = pd.io.sql.read_sql(medications_mapping_query, conn)\n",
    "\n",
    "\n",
    "\n",
    "# medications mapping: move Lithium to the antiepileptics category\n",
    "lithium_list = generate_code_list('Lithium', 'ATC 4th')\n",
    "medications_mapping.loc[(medications_mapping['descendant_concept_id'].isin(lithium_list))&(medications_mapping['rolled_concept_name']=='ANTIPSYCHOTICS'), 'rolled_concept_name'] = 'ANTIEPILEPTICS'\n",
    "medications_mapping['rolled_concept_name'].replace({'ANTIEPILEPTICS': 'MOOD STABILIZERS'}, inplace=True)\n",
    "\n",
    "all_meds = all_meds.merge(medications_mapping[['descendant_concept_id', 'rolled_concept_name', 'rolled_concept_id']], how='left', left_on = 'drug_concept_id', right_on = 'descendant_concept_id')\n",
    "all_meds = all_meds[['person_id','drug_era_id','drug_era_start_date', 'drug_era_end_date', 'cohort_start_date', 'drug_concept_id', 'rolled_concept_name', 'drug_exposure_count']].drop_duplicates()\n",
    "all_meds.loc[all_meds['rolled_concept_name'].isna(), 'rolled_concept_name'] = all_meds.loc[all_meds['rolled_concept_name'].isna(), 'drug_concept_id']\n",
    "\n",
    "list_med_concepts = list(all_meds['rolled_concept_name'])\n",
    "list_med_concepts = [str(i) + '_meds' for i in list_med_concepts]\n",
    "all_meds['rolled_concept_name'] = list_med_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e40f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visits = all_visits.loc[all_visits['person_id'].isin(df_pop['person_id'])]\n",
    "all_visits['cohort_start_date'] = pd.to_datetime(all_visits['cohort_start_date'], format=\"mixed\", dayfirst=False)\n",
    "all_visits['visit_start_date'] = pd.to_datetime(all_visits['visit_start_date'], format=\"mixed\", dayfirst=False)\n",
    "all_visits['visit_end_date'] = pd.to_datetime(all_visits['visit_end_date'], format=\"mixed\", dayfirst=False)\n",
    "all_visits = all_visits.loc[(all_visits['cohort_start_date']-all_visits['visit_end_date']).dt.days >= num_days_prediction]\n",
    "all_visits['days_to_cohort_start'] = (all_visits['cohort_start_date']-all_visits['visit_start_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conds = all_conds.loc[all_conds['person_id'].isin(df_pop['person_id'])]\n",
    "all_conds['cohort_start_date'] = pd.to_datetime(all_conds['cohort_start_date'], format=\"mixed\", dayfirst=False)\n",
    "all_conds['condition_start_date'] = pd.to_datetime(all_conds['condition_start_date'], format=\"mixed\", dayfirst=False)\n",
    "all_conds['days_to_cohort_start'] = (all_conds['cohort_start_date']-all_conds['condition_start_date']).dt.days\n",
    "all_conds = all_conds.loc[all_conds['days_to_cohort_start'] >= num_days_prediction]\n",
    "\n",
    "rollup_conds = \"\"\"WITH rolled_conditions AS (SELECT descendant_concept_id FROM dbo.concept_ancestor WHERE ancestor_concept_id = 441840 AND max_levels_of_separation = 4)\n",
    "                        SELECT rolled_conditions.descendant_concept_id as rolled_concept_id, ca.descendant_concept_id, concept_name as rolled_concept_name\n",
    "                        FROM rolled_conditions\n",
    "                        LEFT JOIN dbo.concept_ancestor as ca ON ca.ancestor_concept_id = rolled_conditions.descendant_concept_id\n",
    "                        LEFT JOIN dbo.concept on rolled_conditions.descendant_concept_id = concept_id\"\"\"\n",
    "\n",
    "conditions_mapping = pd.io.sql.read_sql(rollup_conds, conn)\n",
    "all_conds = all_conds.merge(conditions_mapping[['descendant_concept_id', 'rolled_concept_name', 'rolled_concept_id']], how='left', left_on = 'condition_concept_id', right_on = 'descendant_concept_id')\n",
    "all_conds = all_conds[['person_id','condition_occurrence_id','condition_start_date', 'condition_concept_id', 'concept_name', 'rolled_concept_name', 'cohort_start_date', 'days_to_cohort_start']].drop_duplicates()\n",
    "all_conds.loc[all_conds['rolled_concept_name'].isna(), 'rolled_concept_name'] = all_conds.loc[all_conds['rolled_concept_name'].isna(), 'concept_name']\n",
    "\n",
    "list_cond_concepts = list(all_conds['rolled_concept_name'])\n",
    "list_cond_concepts = [str(i) + '_conds' for i in list_cond_concepts]\n",
    "all_conds['rolled_concept_name'] = list_cond_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11cc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_procedures = all_procedures.loc[all_procedures['person_id'].isin(df_pop['person_id'])]\n",
    "all_procedures['cohort_start_date'] = pd.to_datetime(all_procedures['cohort_start_date'], format=\"mixed\", dayfirst=False)\n",
    "all_procedures['procedure_date'] = pd.to_datetime(all_procedures['procedure_date'], format=\"mixed\", dayfirst=False)\n",
    "all_procedures['days_to_cohort_start'] = (all_procedures['cohort_start_date']-all_procedures['procedure_date']).dt.days\n",
    "all_procedures = all_procedures.loc[all_procedures['days_to_cohort_start'] >= num_days_prediction]\n",
    "\n",
    "rollup_procedures = \"\"\"WITH rolled_procedures AS (SELECT descendant_concept_id FROM dbo.concept_ancestor WHERE ancestor_concept_id = 45889197 AND max_levels_of_separation = 4)\n",
    "                        SELECT rolled_procedures.descendant_concept_id as rolled_concept_id, ca.descendant_concept_id, concept_name as rolled_concept_name\n",
    "                        FROM rolled_procedures\n",
    "                        LEFT JOIN dbo.concept_ancestor as ca ON ancestor_concept_id = rolled_procedures.descendant_concept_id\n",
    "                        LEFT JOIN dbo.concept on rolled_procedures.descendant_concept_id = concept_id\"\"\"\n",
    "\n",
    "procedures_mapping = pd.io.sql.read_sql(rollup_procedures, conn)\n",
    "all_procedures = all_procedures.merge(procedures_mapping[['descendant_concept_id', 'rolled_concept_name', 'rolled_concept_id']], how='left', left_on = 'procedure_concept_id', right_on = 'descendant_concept_id')\n",
    "all_procedures = all_procedures[['person_id','procedure_occurrence_id','procedure_date', 'procedure_concept_id','concept_name', 'rolled_concept_name', 'cohort_start_date', 'days_to_cohort_start']].drop_duplicates()\n",
    "all_procedures.loc[all_procedures['rolled_concept_name'].isna(), 'rolled_concept_name'] = all_procedures.loc[all_procedures['rolled_concept_name'].isna(), 'concept_name']\n",
    "\n",
    "list_procedure_concepts = list(all_procedures['rolled_concept_name'])\n",
    "list_procedure_concepts = [str(i) + '_procedure' for i in list_procedure_concepts]\n",
    "all_procedures['rolled_concept_name'] = list_procedure_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dcb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labs = all_labs.loc[all_labs['person_id'].isin(df_pop['person_id'])]\n",
    "all_labs['cohort_start_date'] = pd.to_datetime(all_labs['cohort_start_date'], format=\"mixed\", dayfirst=False)\n",
    "all_labs['measurement_date'] = pd.to_datetime(all_labs['measurement_date'], format=\"mixed\", dayfirst=False)\n",
    "all_labs['days_to_cohort_start'] = (all_labs['cohort_start_date']-all_labs['measurement_date']).dt.days\n",
    "all_labs = all_labs.loc[all_labs['days_to_cohort_start'] >= num_days_prediction]\n",
    "all_labs['concept_name'] = all_labs['concept_name'].astype(str) + '_lab'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9ee2d",
   "metadata": {},
   "source": [
    "### Delete Rare Features: anything that does not occur in at least 1% of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3dd275",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ccae_validation_set == False:\n",
    "    all_conds = drop_rare_occurrences(all_conds, 'rolled_concept_name', col_id='person_id', size_pop=len(df_pop))\n",
    "    all_meds = drop_rare_occurrences(all_meds, 'rolled_concept_name', col_id='person_id', size_pop=len(df_pop))\n",
    "    all_procedures = drop_rare_occurrences(all_procedures, 'rolled_concept_name', col_id='person_id', size_pop=len(df_pop))\n",
    "    all_labs = drop_rare_occurrences(all_labs, 'measurement_concept_id', col_id='person_id', size_pop=len(df_pop))\n",
    "    all_visits = drop_rare_occurrences(all_visits, 'visit_concept_id', col_id='person_id', size_pop=len(df_pop))\n",
    "else: # get features that overlap with whatever feature set you are using (list_cols)    \n",
    "    with open(path + \"MDCD_11_15_dl_colnames_snomed\", \"rb\") as fp:   #Pickling\n",
    "        list_mdcd_cols = pickle.load(fp)\n",
    "    all_conds = drop_unshared_features(all_conds, 'rolled_concept_name', list_mdcd_cols)\n",
    "    all_meds = drop_unshared_features(all_meds, 'rolled_concept_name', list_mdcd_cols)\n",
    "    all_procedures = drop_unshared_features(all_procedures, 'rolled_concept_name', list_mdcd_cols)\n",
    "    all_labs = drop_unshared_features(all_labs, 'concept_name', list_mdcd_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2897e",
   "metadata": {},
   "source": [
    "### Check for Data Leakage: \n",
    "Minimum times should be at least 90 days and cohort start date should be same across all dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ac569",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = (all_labs['cohort_start_date']-all_labs['measurement_date']).dt.days\n",
    "print('Labs:', check.min(), check.max())\n",
    "\n",
    "check = (all_procedures['cohort_start_date']-all_procedures['procedure_date']).dt.days\n",
    "print('Procedures:', check.min(), check.max())\n",
    "\n",
    "check = (all_conds['cohort_start_date']-all_conds['condition_start_date']).dt.days\n",
    "print('Conditions:', check.min(), check.max())\n",
    "\n",
    "check = (all_meds['cohort_start_date']-all_meds['drug_era_start_date']).dt.days\n",
    "print('Meds (Start of prescription):', check.min(), check.max())\n",
    "check = (all_meds['cohort_start_date']-all_meds['drug_era_end_date']).dt.days\n",
    "print('Meds (End of prescription):', check.min(), check.max())\n",
    "\n",
    "check = (all_visits['cohort_start_date']-all_visits['visit_start_date']).dt.days\n",
    "print('Visits (Start of visit):', check.min(), check.max())\n",
    "check = (all_visits['cohort_start_date']-all_visits['visit_end_date']).dt.days\n",
    "print('Visits (End of visit):', check.min(), check.max())\n",
    "\n",
    "print('Check presence of SCZ:',len(all_conds.loc[all_conds['concept_name'].isin(['Schizophrenia', 'Paranoid schizophrenia'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e13e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_cohort_start = df_pop[['person_id','cohort_start_date']]\n",
    "check_cohort_start = check_cohort_start.merge(all_conds[['person_id','cohort_start_date']].drop_duplicates(),how='left', left_on='person_id', right_on='person_id', suffixes=['_pop','_cond'])\n",
    "check_cohort_start = check_cohort_start.merge(all_visits[['person_id','cohort_start_date']].drop_duplicates(),how='left', left_on='person_id', right_on='person_id', suffixes = ['_old1','_visits'])\n",
    "check_cohort_start = check_cohort_start.merge(all_procedures[['person_id','cohort_start_date']].drop_duplicates(),how='left', left_on='person_id', right_on='person_id', suffixes=['_old2','_pro'])\n",
    "check_cohort_start = check_cohort_start.merge(all_labs[['person_id','cohort_start_date']].drop_duplicates(),how='left', left_on='person_id', right_on='person_id', suffixes=['_old3','_labs'])\n",
    "check_cohort_start = check_cohort_start.merge(all_meds[['person_id','cohort_start_date']].drop_duplicates(),how='left', left_on='person_id', right_on='person_id', suffixes=['_old4','_meds'])\n",
    "check_cohort_start.set_index('person_id',inplace=True)\n",
    "check_cohort_start = check_cohort_start.T\n",
    "num_unique = check_cohort_start.T.apply(lambda x: x.nunique(), axis=1)\n",
    "print('Number of places where cohort start date doesnt align:',(num_unique>1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ca627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate codes\n",
    "print('Conds', 'Unnamed: 0' not in all_conds.columns, len(all_conds) == len(all_conds[['person_id', 'rolled_concept_name', 'condition_start_date', 'condition_occurrence_id']].drop_duplicates()))\n",
    "print('Meds', 'Unnamed: 0' not in all_meds.columns, len(all_meds) == len(all_meds[['person_id', 'rolled_concept_name', 'drug_concept_id', 'drug_era_start_date', 'drug_era_end_date']].drop_duplicates()))\n",
    "print('Visits', 'Unnamed: 0' not in all_visits.columns, len(all_visits) == len(all_visits['visit_occurrence_id'].unique()))\n",
    "print('Procedures', 'Unnamed: 0' not in all_procedures.columns, len(all_procedures) == len(all_procedures[['person_id','rolled_concept_name', 'procedure_concept_id', 'procedure_date', 'procedure_occurrence_id']].drop_duplicates()))\n",
    "print('Labs', 'Unnamed: 0' not in all_labs.columns, len(all_labs) == len(all_labs[['person_id', 'measurement_concept_id', 'measurement_date', 'measurement_id']].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ba5b3",
   "metadata": {},
   "source": [
    "### Make SQL queries for inpatient psych visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPATIENT PSYCH VISITS\n",
    "query = (\"SELECT vo.person_id, vo.visit_occurrence_id, vo.visit_concept_id, co.condition_start_date, vo.visit_start_date, vo.visit_end_date, co.condition_concept_id, c.concept_name as condition_name, p.race_concept_id, p.gender_concept_id \"+\n",
    "         \"FROM dbo.visit_occurrence as vo LEFT JOIN dbo.condition_occurrence as co on co.visit_occurrence_id = vo.visit_occurrence_id \"+\n",
    "         \"LEFT JOIN dbo.concept as c on c.concept_id = co.condition_concept_id \"+\n",
    "         \"LEFT JOIN dbo.person as p on p.person_id = vo.person_id \"+\n",
    "         \"WHERE vo.visit_concept_id = 9201 AND condition_concept_id IN \"+\n",
    "         \"(SELECT DISTINCT concept_id_2 FROM dbo.concept as c LEFT JOIN dbo.concept_relationship on concept_id_1 = concept_id WHERE c.concept_code LIKE 'F%' AND c.vocabulary_id = 'ICD10CM' AND relationship_id = 'Maps to')\")\n",
    "\n",
    "psych_hosp = pd.io.sql.read_sql(query, conn)\n",
    "list_psych_visits = list(psych_hosp['visit_occurrence_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965c2bc",
   "metadata": {},
   "source": [
    "### Create the \"iterative\" population dataframe: \n",
    "- Start at the date of initial psychosis diagnosis, then go every XX days (120 days), cutting off at the censor date (if you go over the censor date, chop to the censor date).\n",
    "- Practically, this means that start date 1 is first visit & end date 1 is psychosis; then start date 2 is psychosis dx date and end date 2 is psychosis dx + 90... \n",
    "- Then, starting at the date of psychosis, go back in XX-day increments for 3 years (9 iterations). The earliest iteration (furthest away from psychosis date) should consist of all prior data, and if a person has less than 3 years of data pre-psychosis, they should have fewer early visits.\n",
    "- Note that start dates are inclusive and end dates are exclusive\n",
    "- **KEEP IN MIND FOR LATER: WE WANT TO PAD AT THE BEGINNING, NOT AT THE END. So then we move each person to be aligned at the end**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = df_pop[['person_id', 'first_visit', 'cohort_start_date', 'psychosis_diagnosis_date']]\n",
    "df_pop['censor_date'] = df_pop['cohort_start_date']-pd.Timedelta(90, 'days')\n",
    "\n",
    "time_per_iter = 120\n",
    "df_pop['0_start'] = df_pop['psychosis_diagnosis_date']\n",
    "df_pop['0_end'] = df_pop['psychosis_diagnosis_date'] + pd.Timedelta(time_per_iter, 'days')\n",
    "df_pop.loc[df_pop['0_end']>df_pop['censor_date'], '0_end'] = df_pop.loc[df_pop['0_end']>df_pop['censor_date'], 'censor_date']\n",
    "\n",
    "# after the loops, remove people for whom 0_start-0_end > 0\n",
    "\n",
    "# FORWARD LOOP: starting at psychosis dx, every XX days till censor date\n",
    "for count in range(1, int(np.ceil(((df_pop['censor_date']-df_pop['psychosis_diagnosis_date']).dt.days/time_per_iter).max()))): \n",
    "    # get the start date as the same day as prev end date and the end date as start + 120 days\n",
    "    df_pop[str(count)+'_start'] = df_pop[str(count-1)+'_end']\n",
    "    df_pop[str(count)+'_end'] = df_pop[str(count)+'_start'] + pd.Timedelta(time_per_iter, 'days')\n",
    "    \n",
    "    # update start/end dates to make sure it is at max, the censor date\n",
    "    df_pop.loc[df_pop[str(count)+'_start'] > df_pop['censor_date'], str(count)+'_start'] = df_pop.loc[df_pop[str(count)+'_start'] > df_pop['censor_date'], 'censor_date']\n",
    "    df_pop.loc[df_pop[str(count)+'_end'] > df_pop['censor_date'], str(count)+'_end'] = df_pop.loc[df_pop[str(count)+'_end'] > df_pop['censor_date'], 'censor_date']\n",
    "    \n",
    "    # if start date == censor date: set start and end to NaT\n",
    "    df_pop.loc[df_pop[str(count)+'_start'] == df_pop['censor_date'], [str(count)+'_start', str(count)+'_end']] = [np.datetime64('NaT'), np.datetime64('NaT')]\n",
    "\n",
    "for count in np.arange(-1, -10, -1):\n",
    "    df_pop[str(count)+'_end'] = df_pop[str(count+1)+'_start']\n",
    "    df_pop[str(count)+'_start'] = df_pop[str(count)+'_end']-pd.Timedelta(time_per_iter, 'days')\n",
    "    \n",
    "    # if the visit starts or ends prior to first_visit, set start/end to first_visit\n",
    "    df_pop.loc[df_pop[str(count)+'_start']<df_pop['first_visit'], str(count)+'_start'] = df_pop.loc[df_pop[str(count)+'_start']<df_pop['first_visit'], 'first_visit']\n",
    "    df_pop.loc[df_pop[str(count)+'_end'] < df_pop['first_visit'], str(count)+'_end'] = df_pop.loc[df_pop[str(count)+'_end'] < df_pop['first_visit'], 'first_visit']\n",
    "    \n",
    "    # if end date == first visit date: set start and end to NaT\n",
    "    df_pop.loc[df_pop[str(count)+'_end'] == df_pop['first_visit'], [str(count)+'_start', str(count)+'_end']] = [np.datetime64('NaT'), np.datetime64('NaT')]\n",
    "    \n",
    "    df_pop[str(count)+'_end'] = pd.to_datetime(df_pop[str(count)+'_end'], format = '%Y-%m-%d')\n",
    "\n",
    "# set iteration -10 so that the end date is -9 start and (if not NaT) the start date is first visit\n",
    "df_pop['-10_end'] = df_pop['-9_start']\n",
    "df_pop['-10_start'] = np.datetime64('NaT')\n",
    "df_pop.loc[~(df_pop['-10_end'].isna()), '-10_start'] = df_pop.loc[~(df_pop['-10_end'].isna()), 'first_visit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bdb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop.columns[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57181d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all \"timesteps\" are at least 1 day\n",
    "for i in np.arange(-10, 30):\n",
    "    df_pop.loc[df_pop[str(i)+'_end']==df_pop[str(i)+'_start'], [str(i)+'_start', str(i)+'_end']] = [np.datetime64('NaT'), np.datetime64('NaT')] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed594569",
   "metadata": {},
   "source": [
    "### Loop through the iterative population dataframe to get the time delta of features for each person in each iteration\n",
    "1. For conditions, procedures, and labs, get all the unique dates that a person got the condition/lab/procedure\n",
    "2. Within each iteration, initialize an empty dataframe that has each person (in that iteration) and each feature. \n",
    "    - Then add a column for within-iter date; this is either the earliest date that they got the feature within that iteration OR the iteration end date (fillna)\n",
    "    - Then add a column for most recent pre-iter date\n",
    "    - Inner merge these (because we can only fill in the time delta if there was a prior value for that feature) and take the difference\n",
    "3. For visits and meds, we need to look at both start and end dates.\n",
    "    - Pre-processing for within iteration: start date needs to be before iteration end date; end date needs to be on or after iteration start date\n",
    "    - We care about the earliest within-iter start date. If there is no start date within the iteration, we will take the end date of the iteration. Do this for each feature.  \n",
    "    - For the end of the last visit, we treat the \"iteration\" as all time prior to this iter_start date and find the most recent end date.\n",
    "    - Keep in mind that in both cases, we cut off the start and end dates so they fit in the appropriate windows. \n",
    "4. Repeat step 2 for the visits + meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6496c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_conds = all_conds[['person_id','rolled_concept_name', 'condition_start_date']].drop_duplicates()\n",
    "keep_conds.rename({'rolled_concept_name':'feature_name', 'condition_start_date':'feature_start_date'}, axis=1, inplace=True)\n",
    "keep_conds = keep_conds.sort_values(['person_id', 'feature_name', 'feature_start_date'])\n",
    "keep_conds['timedelta'] = keep_conds.groupby(['person_id', 'feature_name'])['feature_start_date'].diff().dt.days\n",
    "\n",
    "keep_procedures = all_procedures[['person_id', 'rolled_concept_name', 'procedure_date']].drop_duplicates()\n",
    "keep_procedures.rename({'rolled_concept_name':'feature_name', 'procedure_date':'feature_start_date'}, axis=1, inplace=True)\n",
    "keep_procedures = keep_procedures.sort_values(['person_id', 'feature_name', 'feature_start_date'])\n",
    "keep_procedures['timedelta'] = keep_procedures.groupby(['person_id', 'feature_name'])['feature_start_date'].diff().dt.days\n",
    "\n",
    "keep_labs = all_labs[['person_id', 'concept_name', 'measurement_date']].drop_duplicates()\n",
    "keep_labs.rename({'concept_name':'feature_name', 'measurement_date':'feature_start_date'}, axis=1, inplace=True)\n",
    "keep_labs = keep_labs.sort_values(['person_id', 'feature_name', 'feature_start_date'])\n",
    "keep_labs['timedelta'] = keep_labs.groupby(['person_id', 'feature_name'])['feature_start_date'].diff().dt.days\n",
    "\n",
    "cond_pro_labs = pd.concat([keep_conds, keep_procedures, keep_labs])\n",
    "cond_pro_labs.fillna(0, inplace=True)\n",
    "\n",
    "list_unique_cpl = list(cond_pro_labs['feature_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdeb82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "psych_ip_visits = all_visits.loc[all_visits['visit_occurrence_id'].isin(list_psych_visits)]\n",
    "psych_ip_visits['visit_concept_id'] = 'psych_visits'\n",
    "psych_ip_visits = psych_ip_visits[['person_id', 'visit_concept_id', 'visit_start_date', 'visit_end_date']].drop_duplicates()\n",
    "psych_ip_visits.rename({'visit_concept_id':'feature_name', 'visit_start_date':'feature_start_date', 'visit_end_date':'feature_end_date'}, axis=1, inplace=True)\n",
    "\n",
    "keep_visits = all_visits[['person_id', 'visit_concept_id', 'visit_start_date', 'visit_end_date']].drop_duplicates()\n",
    "keep_visits.rename({'visit_concept_id':'feature_name', 'visit_start_date':'feature_start_date', 'visit_end_date':'feature_end_date'}, axis=1, inplace=True)\n",
    "\n",
    "keep_meds = all_meds[['person_id', 'rolled_concept_name', 'drug_era_start_date', 'drug_era_end_date']].drop_duplicates()\n",
    "keep_meds.rename({'rolled_concept_name':'feature_name', 'drug_era_start_date':'feature_start_date', 'drug_era_end_date':'feature_end_date'}, axis=1, inplace=True)\n",
    "\n",
    "visit_meds = pd.concat([psych_ip_visits, keep_visits, keep_meds])\n",
    "list_unique_vm = list(visit_meds['feature_name'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_timedeltas = []\n",
    "for iteration in tqdm(np.arange(-10, 30)): \n",
    "    temp_df_iter_pop = df_pop.copy()\n",
    "    temp_df_iter_pop['iter_start_date'] = temp_df_iter_pop[str(iteration)+'_start']\n",
    "    temp_df_iter_pop['iter_end_date'] = temp_df_iter_pop[str(iteration)+'_end']\n",
    "\n",
    "    # constrict to people with a valid iteration\n",
    "    temp_df_iter_pop = temp_df_iter_pop.loc[~(temp_df_iter_pop['iter_start_date'].isna())]\n",
    "    temp_df_iter_pop['years_obs'] = (temp_df_iter_pop['iter_end_date']-temp_df_iter_pop['iter_start_date']).dt.days/365\n",
    "\n",
    "    # CONDITIONS LABS PROCEDURES\n",
    "    # for conditions, labs, procedures, just compare the start_date to the cutoff date\n",
    "    within_iter_cond_pro_labs = cond_pro_labs.loc[cond_pro_labs['person_id'].isin(temp_df_iter_pop['person_id'])]\n",
    "    within_iter_cond_pro_labs = within_iter_cond_pro_labs.merge(temp_df_iter_pop[['person_id','iter_start_date', 'iter_end_date']], how = 'left', left_on = 'person_id', right_on = 'person_id')\n",
    "    within_iter_cond_pro_labs = within_iter_cond_pro_labs.loc[within_iter_cond_pro_labs['feature_start_date']>= within_iter_cond_pro_labs['iter_start_date']]\n",
    "    within_iter_cond_pro_labs = within_iter_cond_pro_labs.loc[within_iter_cond_pro_labs['feature_start_date']< within_iter_cond_pro_labs['iter_end_date']]\n",
    "\n",
    "    pre_iter_cond_pro_labs = cond_pro_labs.loc[cond_pro_labs['person_id'].isin(temp_df_iter_pop['person_id'])]\n",
    "    pre_iter_cond_pro_labs = pre_iter_cond_pro_labs.merge(temp_df_iter_pop[['person_id','iter_start_date', 'iter_end_date']], how = 'left', left_on = 'person_id', right_on = 'person_id')\n",
    "    pre_iter_cond_pro_labs = pre_iter_cond_pro_labs.loc[pre_iter_cond_pro_labs['feature_start_date']< pre_iter_cond_pro_labs['iter_start_date']]\n",
    "\n",
    "    if len(within_iter_cond_pro_labs.loc[within_iter_cond_pro_labs['feature_start_date']>=within_iter_cond_pro_labs['iter_end_date']])+len(within_iter_cond_pro_labs.loc[within_iter_cond_pro_labs['feature_start_date']<within_iter_cond_pro_labs['iter_start_date']]) > 0:\n",
    "        print('Leakage in conds/labs/procedures')\n",
    "    if len(pre_iter_cond_pro_labs.loc[pre_iter_cond_pro_labs['feature_start_date']>pre_iter_cond_pro_labs['iter_start_date']]) > 0:\n",
    "        print('Leakage in conds/labs/procedures')\n",
    "\n",
    "    # Sort to ensure order then get the first occurrence\n",
    "    combinations = list(product(list(temp_df_iter_pop['person_id'].unique()), list_unique_cpl))\n",
    "    full_pt_feature_df = pd.DataFrame(columns = ['person_id', 'feature_name'], data = combinations)\n",
    "\n",
    "    # IF SOMETHING EXISTS IN THE ITERATION: GET IT\n",
    "    within_iter_cond_pro_labs = within_iter_cond_pro_labs.sort_values(['person_id', 'feature_name', 'feature_start_date'])\n",
    "    within_iter_cond_pro_labs = within_iter_cond_pro_labs.groupby(['person_id', 'feature_name']).first().reset_index()\n",
    "    full_pt_feature_df = full_pt_feature_df.merge(within_iter_cond_pro_labs[['person_id', 'feature_name', 'feature_start_date']], how='outer', on=['person_id', 'feature_name'])\n",
    "    # ELSE put in the last date in the timestep\n",
    "    full_pt_feature_df = full_pt_feature_df.merge(temp_df_iter_pop[['person_id', 'iter_end_date']], how='outer', on='person_id')\n",
    "    full_pt_feature_df.loc[full_pt_feature_df['feature_start_date'].isna(), 'feature_start_date'] = full_pt_feature_df.loc[full_pt_feature_df['feature_start_date'].isna(), 'iter_end_date']\n",
    "\n",
    "    # Next get the most recent occurrence of a pre-timestep value\n",
    "    pre_iter_cond_pro_labs = pre_iter_cond_pro_labs.groupby(['person_id', 'feature_name']).max()['feature_start_date'].reset_index()\n",
    "    pre_iter_cond_pro_labs.rename({'feature_start_date':'pre_iter_feature_date'}, axis=1, inplace=True)\n",
    "    full_pt_feature_df = full_pt_feature_df.merge(pre_iter_cond_pro_labs, how='inner', on = ['person_id', 'feature_name'])\n",
    "    full_pt_feature_df['time_since_last_feat'] = (full_pt_feature_df['feature_start_date']-full_pt_feature_df['pre_iter_feature_date']).dt.days\n",
    "\n",
    "    # Pivot the table to get person_id as rows and feature_name as columns with timedelta as values\n",
    "    pivot_temp_cond_pro_labs = full_pt_feature_df.pivot(index='person_id', columns='feature_name', values='time_since_last_feat')\n",
    "    pivot_temp_cond_pro_labs.columns.name = None  # Remove the pivot column name\n",
    "    pivot_temp_cond_pro_labs = pivot_temp_cond_pro_labs.reset_index()  # Reset index to bring person_id back as a column\n",
    "    pivot_temp_cond_pro_labs.fillna(0, inplace=True)\n",
    "    \n",
    "    # VISITS AND MEDICATIONS: \n",
    "    \"\"\"create a list of dfs that has patient, iteration and \n",
    "    per feature first and last engagement (first visit start date and \n",
    "    last visit end date per feature)\n",
    "    \"\"\"\n",
    "    # note: for meds and visits, replace iter_end_date with equal_end_date, which is the \n",
    "    # day before the actual end date since is the last day that we are allowing the visit to \"equal\"\n",
    "    # ie visit < iter_end_date but visit <= equal_end_date\n",
    "    \n",
    "    \n",
    "    #for medications and visits, we want to look at \n",
    "    #1. med start date needs to be before iteration end date\n",
    "    #2. med end date needs to be on or after iteration start date\n",
    "    \n",
    "    #3. if med start date is before iteration start date -- make med start date iteration start date\n",
    "    #4. if med end date is after iteration end date -- make med end date iteration end date\n",
    "\n",
    "    # get all the minimum visit/med start dates\n",
    "    temp_visit_meds = visit_meds.loc[visit_meds['person_id'].isin(temp_df_iter_pop['person_id'])]\n",
    "    temp_visit_meds = temp_visit_meds.merge(temp_df_iter_pop[['person_id','iter_start_date', 'iter_end_date']], how = 'left', left_on = 'person_id', right_on = 'person_id')\n",
    "    temp_visit_meds['equal_end_date'] = temp_visit_meds['iter_end_date']-pd.Timedelta(1, 'days')\n",
    "\n",
    "    temp_visit_meds = temp_visit_meds.loc[(temp_visit_meds['feature_start_date']<temp_visit_meds['iter_end_date'])&(temp_visit_meds['feature_end_date']>=temp_visit_meds['iter_start_date'])]\n",
    "    temp_visit_meds.loc[temp_visit_meds['feature_start_date']<temp_visit_meds['iter_start_date'], 'feature_start_date'] = temp_visit_meds.loc[temp_visit_meds['feature_start_date']<temp_visit_meds['iter_start_date'], 'iter_start_date']\n",
    "    temp_visit_meds.loc[temp_visit_meds['feature_end_date']>temp_visit_meds['equal_end_date'], 'feature_end_date'] = temp_visit_meds.loc[temp_visit_meds['feature_end_date']>temp_visit_meds['equal_end_date'], 'equal_end_date']\n",
    "\n",
    "    if len(temp_visit_meds.loc[temp_visit_meds['feature_start_date']>temp_visit_meds['iter_end_date']])+len(temp_visit_meds.loc[temp_visit_meds['feature_end_date']>temp_visit_meds['iter_end_date']]) > 0:\n",
    "        print('Leakage in visit/med ends')\n",
    "    if len(temp_visit_meds.loc[temp_visit_meds['feature_end_date']<temp_visit_meds['iter_start_date']])+len(temp_visit_meds.loc[temp_visit_meds['feature_start_date']<temp_visit_meds['iter_start_date']]) > 0:\n",
    "        print('Leakage in visit/med starts')\n",
    "\n",
    "    temp_visit_meds = temp_visit_meds.groupby(['person_id', 'feature_name']).agg({'feature_start_date':min, 'feature_end_date':max}).reset_index()\n",
    "\n",
    "    combinations = list(product(list(temp_df_iter_pop['person_id'].unique()), list_unique_vm))\n",
    "    full_pt_vm_df = pd.DataFrame(columns = ['person_id', 'feature_name'], data = combinations)\n",
    "    full_pt_vm_df = full_pt_vm_df.merge(temp_visit_meds[['person_id', 'feature_name', 'feature_start_date']], how='outer', on=['person_id', 'feature_name'])\n",
    "    # ELSE put in the last date in the timestep\n",
    "    full_pt_vm_df = full_pt_vm_df.merge(temp_df_iter_pop[['person_id', 'iter_end_date']], how='outer', on='person_id')\n",
    "    full_pt_vm_df.loc[full_pt_vm_df['feature_start_date'].isna(), 'feature_start_date'] = full_pt_vm_df.loc[full_pt_vm_df['feature_start_date'].isna(), 'iter_end_date']\n",
    "\n",
    "    # get all the pre-iteration visit/med start dates\n",
    "    pre_visit_meds = visit_meds.loc[visit_meds['person_id'].isin(temp_df_iter_pop['person_id'])]\n",
    "    pre_visit_meds = pre_visit_meds.merge(temp_df_iter_pop[['person_id','iter_start_date', 'iter_end_date']], how = 'left', left_on = 'person_id', right_on = 'person_id')\n",
    "    pre_visit_meds['equal_end_date'] = pre_visit_meds['iter_start_date']-pd.Timedelta(1, 'days')\n",
    "\n",
    "    pre_visit_meds = pre_visit_meds.loc[(pre_visit_meds['feature_start_date']<pre_visit_meds['iter_start_date'])]\n",
    "    pre_visit_meds.loc[pre_visit_meds['feature_end_date']>pre_visit_meds['equal_end_date'], 'feature_end_date'] = pre_visit_meds.loc[pre_visit_meds['feature_end_date']>pre_visit_meds['equal_end_date'], 'equal_end_date']\n",
    "\n",
    "    if len(pre_visit_meds.loc[pre_visit_meds['feature_start_date']>pre_visit_meds['iter_start_date']])+len(pre_visit_meds.loc[pre_visit_meds['feature_end_date']>pre_visit_meds['iter_start_date']]) > 0:\n",
    "        print('Leakage in visit/med pre-iter')\n",
    "\n",
    "    pre_visit_meds = pre_visit_meds.groupby(['person_id', 'feature_name']).agg({'feature_end_date':max}).reset_index()\n",
    "    full_pt_vm_df = full_pt_vm_df.merge(pre_visit_meds, how='inner', on=['person_id', 'feature_name'])\n",
    "\n",
    "    full_pt_vm_df['time_since_last_feat'] = (full_pt_vm_df['feature_start_date']-full_pt_vm_df['feature_end_date']).dt.days\n",
    "\n",
    "    # Pivot the table to get person_id as rows and feature_name as columns with timedelta as values\n",
    "    pivot_temp_meds_visits = full_pt_vm_df.pivot(index='person_id', columns='feature_name', values='time_since_last_feat')\n",
    "    pivot_temp_meds_visits.columns.name = None  # Remove the pivot column name\n",
    "    pivot_temp_meds_visits = pivot_temp_meds_visits.reset_index()  # Reset index to bring person_id back as a column\n",
    "    pivot_temp_meds_visits.fillna(0, inplace=True)\n",
    "\n",
    "    full_pivot_table = pivot_temp_cond_pro_labs.merge(pivot_temp_meds_visits, how='outer', on='person_id')\n",
    "    full_pivot_table['iteration'] = iteration\n",
    "    \n",
    "    list_timedeltas.append(full_pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_timedeltas = pd.concat(list_timedeltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ccae_validation_set == True:\n",
    "    missing_cols = list(set(list_mdcd_cols).difference(all_timedeltas.columns))\n",
    "    all_timedeltas.loc[:,missing_cols] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14396a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ranked iterations, where the smallest iter per patient is 0 and the largest is (max)\n",
    "ranked_vals = all_timedeltas.reset_index().groupby('person_id')['iteration'].rank(method='first').values\n",
    "all_timedeltas['ranked_iteration'] = ranked_vals\n",
    "\n",
    "all_timedeltas.fillna(0, inplace=True)\n",
    "print(all_timedeltas['ranked_iteration'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bb3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_timedeltas.to_csv(int_path + 'CCAE_11_15_grud_timedeltas_snomed_sharedfeats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49cd3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fe331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
