{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce51bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pymssql\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import gc\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b58a2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'PATH'\n",
    "conn = 'CONNECTION TO SQL SERVER'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526a37f",
   "metadata": {},
   "source": [
    "#### ICD codes and their corresponding concept_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca98edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['concept_id', 'concept_name', 'domain_id', 'vocabulary_id', 'concept_class_id', 'standard_concept', 'concept_code', 'valid_start_date', 'valid_end_date', 'invalid_reason']\n",
    "psychosis_codeset = pd.read_csv('codes_mappings/psychosis_concepts.csv', names = colnames)\n",
    "\n",
    "# filter out schizophreniform disorder. Note that 295 is not included at all \n",
    "psychosis_codeset = psychosis_codeset.loc[psychosis_codeset['concept_code'] != 'F20.81']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57b9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_exclusive_mappings(psychosis_codes):\n",
    "    \"\"\"\n",
    "    This function takes in a list of ICD codes and returns all of the \n",
    "    snomed mappings, divided into \"exclusive\" (this SNOMED term only \n",
    "    maps to ICD codes in the psychosis_codes list) and \"nonexclusive\" \n",
    "    (this snomed term maps to ICD codes both on and not on the psychosis_codes list)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # get all ICD codes and their SNOMED Mappings\n",
    "    icd_to_snomed_query = \"\"\"SELECT icd_c.concept_name as icd_concept_name, icd_c.concept_code, icd_c.vocabulary_id, concept_id_1 as icd_mapping_concept, concept_id_2 as snomed_mapping_concept, snomed_c.concept_name as snomed_concept_name, snomed_c.standard_concept\n",
    "    FROM dbo.concept as icd_c\n",
    "    LEFT JOIN dbo.concept_relationship AS cr ON cr.concept_id_1 = icd_c.concept_id\n",
    "    LEFT JOIN dbo.concept AS snomed_c ON cr.concept_id_2 = snomed_c.concept_id\n",
    "    WHERE icd_c.vocabulary_id IN ('ICD9CM', 'ICD10CM') AND relationship_id = 'Maps to'\n",
    "    \"\"\"\n",
    "\n",
    "    icd_to_snomed_df = pd.io.sql.read_sql(icd_to_snomed_query, conn)\n",
    "    \n",
    "    # get all snomed conditions and their respective ICD Codes\n",
    "    snomed_to_icd_query = \"\"\"SELECT snomed_c.concept_id as snomed_concept_id, snomed_c.concept_name as snomed_concept_name, snomed_c.standard_concept, icd_c.concept_id as icd_concept_id, icd_c.concept_name as icd_concept_name, icd_c.vocabulary_id, icd_c.concept_code\n",
    "    FROM dbo.concept as snomed_c\n",
    "    LEFT JOIN dbo.concept_relationship as cr ON snomed_c.concept_id = cr.concept_id_1\n",
    "    LEFT JOIN dbo.concept as icd_c ON cr.concept_id_2 = icd_c.concept_id\n",
    "    WHERE icd_c.vocabulary_id IN ('ICD9CM', 'ICD10CM') AND relationship_id = 'Mapped from'\n",
    "    \"\"\"\n",
    "\n",
    "    snomed_to_icd_df = pd.io.sql.read_sql(snomed_to_icd_query, conn)\n",
    "    \n",
    "    broad_psychosis_codes = icd_to_snomed_df.loc[icd_to_snomed_df['concept_code'].isin(psychosis_codes)]\n",
    "    snomed_to_icd_psychosis = snomed_to_icd_df.loc[snomed_to_icd_df['snomed_concept_id'].isin(broad_psychosis_codes['snomed_mapping_concept'])]\n",
    "\n",
    "    # Get all snomed codes in broad psychosis_codes that only map to psychosis ICD codes (list_keep)\n",
    "    list_toss = []\n",
    "    for i in snomed_to_icd_psychosis['snomed_concept_id'].unique():\n",
    "        icds_per_snomeds = (snomed_to_icd_psychosis.loc[snomed_to_icd_psychosis['snomed_concept_id']==i, 'concept_code'].unique())\n",
    "        if len(set(icds_per_snomeds).difference(psychosis_codeset['concept_code'])) > 0:\n",
    "            list_toss.append(snomed_to_icd_psychosis.loc[snomed_to_icd_psychosis['snomed_concept_id']==i, 'snomed_concept_name'].unique()[0])\n",
    "            \n",
    "    list_keep = []\n",
    "    for i in snomed_to_icd_psychosis['snomed_concept_id'].unique():\n",
    "        icds_per_snomeds = (snomed_to_icd_psychosis.loc[snomed_to_icd_psychosis['snomed_concept_id']==i, 'concept_code'].unique())\n",
    "        if len(set(icds_per_snomeds).difference(psychosis_codeset['concept_code'])) == 0:\n",
    "            list_keep.append(snomed_to_icd_psychosis.loc[snomed_to_icd_psychosis['snomed_concept_id']==i, 'snomed_concept_name'].unique()[0])\n",
    "    \n",
    "    return list_keep, list_toss, snomed_to_icd_psychosis, broad_psychosis_codes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1db507f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3377353/2196887354.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  icd_to_snomed_df = pd.io.sql.read_sql(icd_to_snomed_query, conn)\n",
      "/tmp/ipykernel_3377353/2196887354.py:28: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  snomed_to_icd_df = pd.io.sql.read_sql(snomed_to_icd_query, conn)\n"
     ]
    }
   ],
   "source": [
    "# More restrictive Bipolar I codes:\n",
    "exclusive_codes, nonexclusive_codes, snomed_to_icd, icd_to_snomed = identify_exclusive_mappings(psychosis_codeset['concept_code'])\n",
    "exclusive_concept_codes = set(icd_to_snomed.loc[icd_to_snomed['snomed_concept_name'].isin(exclusive_codes), 'concept_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9edb0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3377353/3273142272.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  all_scz_codes = pd.io.sql.read_sql(all_scz_codes_query, conn)\n"
     ]
    }
   ],
   "source": [
    "# get schziophrenia codes\n",
    "all_scz_codes_query = (\"SELECT c_new.concept_id as standard_concept_id, c_icd10.concept_code as icd_code, c_new.concept_name as standard_concept_name, c_icd10.concept_name as icd_name FROM dbo.concept as c_icd10 LEFT JOIN dbo.concept_relationship as rel on rel.concept_id_1 = c_icd10.concept_id \"+\n",
    "                \"LEFT JOIN dbo.concept as c_rel on rel.concept_id_2 = c_rel.concept_id \"+\n",
    "                \"LEFT JOIN dbo.concept_ancestor as ca ON ca.ancestor_concept_id = rel.concept_id_2 \"+\n",
    "                \"LEFT JOIN dbo.concept as c_new on c_new.concept_id = ca.descendant_concept_id \" +\n",
    "                \"WHERE (rel.relationship_id = 'Maps to' AND c_new.standard_concept = 'S') \"+\n",
    "                \"AND ((c_icd10.concept_code LIKE '295%' AND c_icd10.vocabulary_id = 'ICD9CM') \"+\n",
    "                \"OR ((c_icd10.concept_code LIKE 'F2[05]%' AND c_icd10.vocabulary_id = 'ICD10CM')))\")\n",
    "\n",
    "all_scz_codes = pd.io.sql.read_sql(all_scz_codes_query, conn)\n",
    "all_scz_codes = all_scz_codes.loc[~(all_scz_codes['standard_concept_id'].isin([444434, 4184004, 4263364]))]\n",
    "# all_scz_codes.to_csv('all_scz_codes.csv')\n",
    "all_scz_codes = pd.read_csv('all_scz_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76a1543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove codes that are related to schizophrenia\n",
    "exclusive_concept_ids = list(icd_to_snomed.loc[icd_to_snomed['snomed_concept_name'].isin(exclusive_codes), 'snomed_mapping_concept'].unique())\n",
    "psychosis_codes = list(set(exclusive_concept_ids).difference(all_scz_codes['standard_concept_id']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca7da814",
   "metadata": {},
   "source": [
    "# Create Cohort\n",
    "1. (In DataGrip) Get all the patients with SCZ/schizoaffective disorder and 3 years of prior observation and save them to the schizophrenia_incidence table\n",
    "2. (In DataGrip) Get all patients who have an episode of psychosis (incl. schizophrenia) and 3 years of observation overall -- save this into results as sychosis_cohort\n",
    "3. Pull all people with SCZ and make sure that a. they have an accurate cohort start date; b. they have a valid psychosis diagnosis prior; c. they have no history of schizophreniform disorder\n",
    "4. Pull all people with psychosis and make sure a. they have no history of schziophrenia; b. they have a valid psychosis diagnosis (with an accurate psychosis diagnosis date); c. they have no history of schizophreniform disorder\n",
    "5. Make sure everyone is between 10 and 35 years at \"cohort start\" (SCZ diagnosis or observation period end date)\n",
    "6. Make sure that the first observed schizophrenia is after psychosis\n",
    "7. Combine dataframes (SCZ and No SCZ) and add SCZ \"flag\"\n",
    "8. Get all conditions in 3 years prior to cohort start for both of the above tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae325486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3377353/2283391017.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_psychosis_all = pd.io.sql.read_sql(\"SELECT pc.*, year_of_birth, race_concept_id, gender_concept_id FROM results.ak4885_psychosis_cohort_3yrs as pc LEFT JOIN dbo.person as p ON p.person_id = pc.person_id\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nans 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3377353/2283391017.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_scz_all = pd.io.sql.read_sql(\"SELECT sc.*, year_of_birth, race_concept_id, gender_concept_id FROM results.ak4885_schizophrenia_cohort_3yrs as sc LEFT JOIN dbo.person as p ON p.person_id = sc.person_id\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nans SCZ 0\n",
      "2973474 45129 1.495029323167041\n"
     ]
    }
   ],
   "source": [
    "# 1, 2. get everyone from super broad schizophrenia and psychosis cohorts\n",
    "df_psychosis_all = pd.io.sql.read_sql(\"SELECT pc.*, year_of_birth, race_concept_id, gender_concept_id FROM results.psychosis_cohort_3yrs as pc LEFT JOIN dbo.person as p ON p.person_id = pc.person_id\", conn)\n",
    "print('Nans', df_psychosis_all.isna().sum().sum())\n",
    "\n",
    "df_scz_all = pd.io.sql.read_sql(\"SELECT sc.*, year_of_birth, race_concept_id, gender_concept_id FROM results.schizophrenia_cohort_3yrs as sc LEFT JOIN dbo.person as p ON p.person_id = sc.person_id\", conn)\n",
    "print('Nans SCZ', df_scz_all.isna().sum().sum())\n",
    "\n",
    "\n",
    "df_scz_all = df_scz_all.merge(df_psychosis_all[['person_id', 'psychosis_dx_date']], how='left', left_on = 'person_id', right_on = 'person_id')\n",
    "if df_scz_all.isna().sum().sum() > 0:\n",
    "    print('Undefined psychosis diagnosis date after merge')\n",
    "df_psychosis_all = df_psychosis_all.loc[~df_psychosis_all['person_id'].isin(list(df_scz_all['person_id']))]\n",
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1869328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scz_all.rename({'cohort_end_date':'end_date'}, axis=1, inplace=True)\n",
    "df_psychosis_all.rename({'cohort_end_date':'end_date'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a02849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3377353/2032471230.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  all_sz_dx = pd.io.sql.read_sql(all_sz_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45129\n"
     ]
    }
   ],
   "source": [
    "## NOTE: this is an artifact of when we want at least n diagnoses\n",
    "# limit schizophrenia cohort to people with at least 1 diagnosis\n",
    "all_sz_query = (\"SELECT person_id, condition_concept_id, condition_start_date FROM dbo.condition_occurrence WHERE condition_concept_id IN (SELECT c_new.concept_id FROM dbo.concept as c_icd10 LEFT JOIN dbo.concept_relationship as rel on rel.concept_id_1 = c_icd10.concept_id \"+\n",
    "                \"LEFT JOIN dbo.concept as c_rel on rel.concept_id_2 = c_rel.concept_id \"+\n",
    "                \"LEFT JOIN dbo.concept_ancestor as ca ON ca.ancestor_concept_id = rel.concept_id_2 \"+\n",
    "                \"LEFT JOIN dbo.concept as c_new on c_new.concept_id = ca.descendant_concept_id \" +\n",
    "                \"WHERE (rel.relationship_id = 'Maps to' AND c_new.standard_concept = 'S') \"+\n",
    "                \"AND ((c_icd10.concept_code LIKE '295%' AND c_icd10.vocabulary_id = 'ICD9CM') \"+\n",
    "                \"OR ((c_icd10.concept_code LIKE 'F2[05].%' OR c_icd10.concept_code = 'F20.81' AND c_icd10.vocabulary_id = 'ICD10CM'))))\")\n",
    "\n",
    "all_sz_dx = pd.io.sql.read_sql(all_sz_query, conn)\n",
    "\n",
    "# remove schizophreniform disorder as \"acceptable SCZ diagnosis\"\n",
    "all_sz_dx = all_sz_dx.loc[~all_sz_dx['condition_concept_id'].isin([444434, 4184004, 4263364])]\n",
    "\n",
    "dx_twice_pids = all_sz_dx[['person_id','condition_start_date']].drop_duplicates().groupby('person_id').count()['condition_start_date'] >= 1\n",
    "df_scz_all = df_scz_all.loc[df_scz_all['person_id'].isin(list(dx_twice_pids[dx_twice_pids==True].index))]\n",
    "print(len(df_scz_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c16700da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3377353/3482507350.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  all_conds_scz = pd.io.sql.read_sql (\"SELECT DISTINCT sc.person_id, condition_start_date, condition_concept_id FROM results.ak4885_schizophrenia_cohort_3yrs as sc LEFT JOIN dbo.condition_occurrence as co ON co.person_id = sc.person_id\", conn)\n",
      "/tmp/ipykernel_3377353/3482507350.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  scz_conds_scz['condition_start_date'] = pd.to_datetime(scz_conds_scz['condition_start_date'], format='%Y-%m-%d')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26385\n"
     ]
    }
   ],
   "source": [
    "# get all conditions for people in the schizophrenia cohort\n",
    "all_conds_scz = pd.io.sql.read_sql (\"SELECT DISTINCT sc.person_id, condition_start_date, condition_concept_id FROM results.schizophrenia_cohort_3yrs as sc LEFT JOIN dbo.condition_occurrence as co ON co.person_id = sc.person_id\", conn) \n",
    "\n",
    "## 3a. Make sure that there is an appropriate cohort_start_date\n",
    "scz_conds_scz = all_conds_scz.loc[all_conds_scz['condition_concept_id'].isin(all_scz_codes['standard_concept_id'])]\n",
    "scz_conds_scz['condition_start_date'] = pd.to_datetime(scz_conds_scz['condition_start_date'], format='%Y-%m-%d')\n",
    "\n",
    "scz_diagnosis_date = scz_conds_scz.groupby('person_id').min()['condition_start_date']\n",
    "scz_diagnosis_date.name = \"scz_diagnosis_date\"\n",
    "scz_conds_scz = scz_conds_scz.merge(scz_diagnosis_date, left_on='person_id', right_index=True)\n",
    "scz_conds_scz = scz_conds_scz.loc[scz_conds_scz['scz_diagnosis_date']==scz_conds_scz['condition_start_date']]\n",
    "\n",
    "df_scz_all = df_scz_all.merge(scz_conds_scz[['person_id', 'scz_diagnosis_date']].drop_duplicates(), how='inner', left_on = 'person_id', right_on='person_id')\n",
    "df_scz_all['cohort_start_date'] = df_scz_all['scz_diagnosis_date']\n",
    "\n",
    "## 3b. make sure that there is at least one \"acceptable\" psychosis code preceeding SCZ dx\n",
    "##(also store the initial psychosis code, accurate psychosis dx date)\n",
    "psych_conds_scz = all_conds_scz.loc[all_conds_scz['condition_concept_id'].isin(psychosis_codes)]\n",
    "psych_diagnosis_date = psych_conds_scz.groupby('person_id').min()['condition_start_date']\n",
    "psych_diagnosis_date.name = \"psychosis_diagnosis_date\"\n",
    "psych_conds_scz = psych_conds_scz.merge(psych_diagnosis_date, left_on='person_id', right_index=True)\n",
    "psych_conds_scz = psych_conds_scz.loc[psych_conds_scz['psychosis_diagnosis_date']==psych_conds_scz['condition_start_date']]\n",
    "df_scz_all = df_scz_all.merge(psych_conds_scz[['person_id', 'psychosis_diagnosis_date']], how='inner', left_on='person_id', right_on = 'person_id')\n",
    "df_scz_all = df_scz_all[['cohort_definition_id', 'person_id', \n",
    "                         'cohort_start_date', 'end_date', \n",
    "                         'year_of_birth', 'race_concept_id', \n",
    "                         'gender_concept_id', 'scz_diagnosis_date', \n",
    "                         'psychosis_diagnosis_date']].drop_duplicates()\n",
    "scz_initial_psychosis = psych_conds_scz[['person_id', 'condition_concept_id', 'psychosis_diagnosis_date']]\n",
    "print(len(df_scz_all))\n",
    "\n",
    "## 3c. Remove anyone with a history of schizophreniform disorder\n",
    "schizophreniform_scz = all_conds_scz.loc[all_conds_scz['condition_concept_id'].isin([444434, 4184004, 4263364])]\n",
    "df_scz_all = df_scz_all.loc[~(df_scz_all['person_id'].isin(schizophreniform_scz['person_id']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aec3417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3377353/1385949647.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  for chunk in pd.io.sql.read_sql(psych_conds_query, conn, chunksize=500000):\n"
     ]
    }
   ],
   "source": [
    "# get all conditions for people in the psychosis cohort\n",
    "psych_conds_query = \"SELECT DISTINCT pc.person_id, condition_start_date, condition_concept_id FROM results.psychosis_cohort_3yrs as pc LEFT JOIN dbo.condition_occurrence as co ON co.person_id = pc.person_id WHERE condition_concept_id > 0\"\n",
    "\n",
    "list_chunks = []\n",
    "for chunk in pd.io.sql.read_sql(psych_conds_query, conn, chunksize=500000):\n",
    "    list_chunks.append(chunk.loc[chunk['person_id'].isin(df_psychosis_all['person_id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b2d1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conds_psych = pd.concat(list_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4342e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295446\n"
     ]
    }
   ],
   "source": [
    "##4a. Make sure that there are no conditions of scz or schizophreniform\n",
    "scz_conds_psych = all_conds_psych.loc[all_conds_psych['condition_concept_id'].isin(all_scz_codes['standard_concept_id'])]\n",
    "df_psychosis_all = df_psychosis_all.loc[~(df_psychosis_all['person_id'].isin(scz_conds_psych['person_id']))]\n",
    "\n",
    "## 4b. make sure that there is at least one \"acceptable\" psychosis code \n",
    "##(also store the initial psychosis code, accurate psychosis dx date)\n",
    "psych_conds_psych = all_conds_psych.loc[all_conds_psych['condition_concept_id'].isin(psychosis_codes)]\n",
    "psych_diagnosis_date = psych_conds_psych.groupby('person_id').min()['condition_start_date']\n",
    "psych_diagnosis_date.name = \"psychosis_diagnosis_date\"\n",
    "psych_conds_psych = psych_conds_psych.merge(psych_diagnosis_date, left_on='person_id', right_index=True)\n",
    "psych_conds_psych = psych_conds_psych.loc[psych_conds_psych['psychosis_diagnosis_date']==psych_conds_psych['condition_start_date']]\n",
    "df_psychosis_all = df_psychosis_all.merge(psych_conds_psych[['person_id', 'psychosis_diagnosis_date']], how='inner', left_on='person_id', right_on = 'person_id')\n",
    "df_psychosis_all['scz_diagnosis_date'] = np.nan\n",
    "df_psychosis_all['cohort_start_date'] = df_psychosis_all['end_date']\n",
    "df_psychosis_all = df_psychosis_all[['cohort_definition_id', 'person_id', \n",
    "                         'cohort_start_date', 'end_date', \n",
    "                         'year_of_birth', 'race_concept_id', \n",
    "                         'gender_concept_id', 'scz_diagnosis_date', \n",
    "                         'psychosis_diagnosis_date']].drop_duplicates()\n",
    "psych_initial_psychosis = psych_conds_psych[['person_id', 'condition_concept_id', 'psychosis_diagnosis_date']]\n",
    "psych_initial_psychosis = psych_initial_psychosis.loc[psych_initial_psychosis['person_id'].isin(df_psychosis_all['person_id'])]\n",
    "all_conds_psych = all_conds_psych.loc[all_conds_psych['person_id'].isin(df_psychosis_all['person_id'])]\n",
    "\n",
    "## 4c. remove anyone with a history of schizophreniform disorder\n",
    "schizophreniform_psych = all_conds_psych.loc[all_conds_psych['condition_concept_id'].isin([444434, 4184004, 4263364])]\n",
    "df_psychosis_all = df_psychosis_all.loc[~(df_psychosis_all['person_id'].isin(schizophreniform_psych['person_id']))]\n",
    "\n",
    "all_conds_psych = all_conds_psych.loc[all_conds_psych['person_id'].isin(df_psychosis_all['person_id'])]\n",
    "\n",
    "print(len(df_psychosis_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3967d491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106983 12564 10.509674019423324\n"
     ]
    }
   ],
   "source": [
    "# 5. AGE AT COHORT INDEX\n",
    "df_psychosis_all['end_date'] = pd.to_datetime(df_psychosis_all['end_date'], format = '%Y-%m-%d')\n",
    "df_psychosis_all['year_of_birth'] = pd.to_datetime(df_psychosis_all['year_of_birth'], format = '%Y')\n",
    "df_psychosis_all['age_diagnosis'] = (df_psychosis_all['end_date']-df_psychosis_all['year_of_birth']).dt.days/365\n",
    "\n",
    "df_psychosis_all = df_psychosis_all.loc[df_psychosis_all['age_diagnosis']<=35]\n",
    "df_psychosis_all = df_psychosis_all.loc[df_psychosis_all['age_diagnosis']>=10]\n",
    "\n",
    "df_scz_all['cohort_start_date'] = pd.to_datetime(df_scz_all['cohort_start_date'], format = '%Y-%m-%d')\n",
    "df_scz_all['year_of_birth'] = pd.to_datetime(df_scz_all['year_of_birth'], format = '%Y')\n",
    "df_scz_all['age_diagnosis'] = (df_scz_all['cohort_start_date']-df_scz_all['year_of_birth']).dt.days/365\n",
    "\n",
    "df_scz_all = df_scz_all.loc[df_scz_all['age_diagnosis']<=35]\n",
    "df_scz_all = df_scz_all.loc[df_scz_all['age_diagnosis']>=10]\n",
    "\n",
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa623a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conds_psych = all_conds_psych.loc[all_conds_psych['person_id'].isin(df_psychosis_all['person_id'])]\n",
    "all_conds_scz = all_conds_scz.loc[all_conds_scz['person_id'].isin(df_scz_all['person_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7b29292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106983 8311 7.208527763803841\n"
     ]
    }
   ],
   "source": [
    "# 6. First SCZ Diagnosis is AFTER first psychosis diagnosis\n",
    "df_scz_all['psychosis_diagnosis_date'] = pd.to_datetime(df_scz_all['psychosis_diagnosis_date'])\n",
    "df_scz_all = df_scz_all.loc[df_scz_all['cohort_start_date']>df_scz_all['psychosis_diagnosis_date']]\n",
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb1a2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. combine data\n",
    "all_conds_scz = all_conds_scz.loc[all_conds_scz['person_id'].isin(df_scz_all['person_id'])]\n",
    "all_conds_scz['sz_flag'] = 1\n",
    "all_conds_psych['sz_flag'] = 0\n",
    "\n",
    "all_conds = pd.concat([all_conds_scz, all_conds_psych])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f086cadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3377353/171304710.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_pop = pd.concat([df_psychosis_all, df_scz_all])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115294 7.208527763803841\n"
     ]
    }
   ],
   "source": [
    "df_psychosis_all['sz_flag'] = 0\n",
    "df_scz_all['sz_flag'] = 1\n",
    "df_pop = pd.concat([df_psychosis_all, df_scz_all])\n",
    "print(len(df_pop), sum(df_pop['sz_flag'])*100/len(df_pop))\n",
    "\n",
    "all_conds = all_conds.merge(df_pop[['person_id','cohort_start_date']], how='inner', left_on = 'person_id', right_on = 'person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dd6b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Restrict all conds to 7 years before index to get continuous care\n",
    "all_conds['condition_start_date'] = pd.to_datetime(all_conds['condition_start_date'], format = '%Y-%m-%d')\n",
    "all_conds['cohort_start_date'] = pd.to_datetime(all_conds['cohort_start_date'], format = '%Y-%m-%d')\n",
    "\n",
    "all_conds = all_conds.loc[(all_conds['cohort_start_date']-all_conds['condition_start_date']).dt.days<=2555]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62046ffd",
   "metadata": {},
   "source": [
    "# Constrict cohort based on continuous care\n",
    "### First drop instances of conditions where the condition concept id is not defined\n",
    "\n",
    "\n",
    "### To ensure that there is at least 1 service contact per year\n",
    "\n",
    "Calculate the differences between consecutive condition occurrences for each patient -- do this by making sure that:\n",
    "1. there are at least 7 unique dates that there is a visit \n",
    "2. there's at least one visit > 6 years before diagnosis\n",
    "3. the max difference between consecutive dates is 1 year (inclusive)\n",
    "\n",
    "# Changed to be 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1011c512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done datetime conversions\n",
      "done getting at least 7 unique dates for visits\n",
      "done w/ earliest visit prior to 6 years pre-cohort start\n",
      "done grouping for 1 year between conditions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 110944/110944 [00:12<00:00, 8874.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# drop undefined conditions\n",
    "conds_dates = all_conds[['person_id', 'condition_start_date', 'cohort_start_date']].drop_duplicates()\n",
    "print('done datetime conversions')\n",
    "\n",
    "# at least 7 unique dates for visits\n",
    "conds_patients = conds_dates.groupby('person_id').count()\n",
    "yearly_service_pids = list(conds_patients.loc[conds_patients['condition_start_date'] >= 3].index)\n",
    "print('done getting at least 7 unique dates for visits')\n",
    "\n",
    "# at least 1 visit > 6 years before diagnosis\n",
    "conds_dates = conds_dates.loc[conds_dates['person_id'].isin(yearly_service_pids)]\n",
    "yearly_service_pids = list(conds_dates.loc[(conds_dates['cohort_start_date']-conds_dates['condition_start_date']).dt.days > 730]['person_id'].unique())\n",
    "print('done w/ earliest visit prior to 6 years pre-cohort start')\n",
    "\n",
    "# maximum of 1 year between conditions\n",
    "conds_dates = conds_dates.loc[conds_dates['person_id'].isin(yearly_service_pids)]\n",
    "conds_dates_grouped = conds_dates.groupby(['person_id'])['condition_start_date'].apply(np.hstack)\n",
    "conds_dates_arr = conds_dates_grouped.reset_index().values\n",
    "print('done grouping for 1 year between conditions')\n",
    "\n",
    "yearly_service_pids = []\n",
    "for ind in tqdm(range(0,len(conds_dates_arr))):\n",
    "    if len(conds_dates_arr[ind,1])>1:\n",
    "        conds_dates_arr[ind,1].sort()\n",
    "        if(max(np.diff(conds_dates_arr[ind,1])).days<=365):\n",
    "            yearly_service_pids.append(conds_dates_arr[ind,0])\n",
    "print(len(yearly_service_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fddf8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69633 5.200120632458748\n"
     ]
    }
   ],
   "source": [
    "df_pop = df_pop.loc[df_pop['person_id'].isin(yearly_service_pids)]\n",
    "print(len(df_pop), sum(df_pop['sz_flag'])*100/len(df_pop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08601684",
   "metadata": {},
   "source": [
    "## Maximum of 45 days with no insurance coverage\n",
    "- Get insurance information from all people with at least 7 years observation and then limit to only the people in with at least 1 service visit per year\n",
    "- Combine all of the overlapping payer periods, with a grace period of 45 days between coverage periods\n",
    "\n",
    "# Change to 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8c4858f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3377353/529173210.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  insurance_df = pd.io.sql.read_sql(insurance_query, conn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47722149"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_query = (\"SELECT ppp.PERSON_ID, ppp.PAYER_PLAN_PERIOD_START_DATE, ppp.PAYER_PLAN_PERIOD_END_DATE, ppp.PAYER_SOURCE_VALUE \"+\n",
    "                   \"FROM dbo.PAYER_PLAN_PERIOD as ppp LEFT JOIN dbo.OBSERVATION_PERIOD as op ON op.person_id = ppp.PERSON_ID \"+\n",
    "                   \"WHERE DATEDIFF(day, OBSERVATION_PERIOD_START_DATE, OBSERVATION_PERIOD_END_DATE) > 1095\")\n",
    "insurance_df = pd.io.sql.read_sql(insurance_query, conn)\n",
    "len(insurance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff0f540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df = insurance_df.loc[insurance_df['PERSON_ID'].isin(yearly_service_pids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d3c226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3377353/2031665119.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  merged_insurance_df = insurance_df.groupby([\"PERSON_ID\"], as_index=False).apply(\n"
     ]
    }
   ],
   "source": [
    "insurance_df['PAYER_PLAN_PERIOD_START_DATE'] =  pd.to_datetime(insurance_df['PAYER_PLAN_PERIOD_START_DATE'], format='%Y-%m-%d')\n",
    "insurance_df['PAYER_PLAN_PERIOD_END_DATE'] =  pd.to_datetime(insurance_df['PAYER_PLAN_PERIOD_END_DATE'], format='%Y-%m-%d')\n",
    "\n",
    "# https://stackoverflow.com/questions/68714898/merge-consecutive-and-overlapping-date-ranges\n",
    "\n",
    "merged_insurance_df = insurance_df.groupby([\"PERSON_ID\"], as_index=False).apply(\n",
    "    lambda d: d.sort_values([\"PAYER_PLAN_PERIOD_END_DATE\", \"PAYER_PLAN_PERIOD_START_DATE\"])\n",
    "    .assign(\n",
    "        grp=lambda d: (\n",
    "            ~(d[\"PAYER_PLAN_PERIOD_START_DATE\"] <= (d[\"PAYER_PLAN_PERIOD_END_DATE\"].shift() + pd.Timedelta(days=45)))\n",
    "        ).cumsum()\n",
    "    )\n",
    "    .groupby([\"PERSON_ID\", \"grp\"], as_index=False)\n",
    "    .agg({\"PAYER_PLAN_PERIOD_START_DATE\": \"min\", \"PAYER_PLAN_PERIOD_END_DATE\": \"max\"})\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8641f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63062\n"
     ]
    }
   ],
   "source": [
    "df_pop['cohort_start_date'] =  pd.to_datetime(df_pop['cohort_start_date'], format='%Y-%m-%d')\n",
    "\n",
    "insurance_check_df = df_pop.merge(merged_insurance_df, how = 'left', left_on = 'person_id', right_on = 'PERSON_ID')\n",
    "eligible_pids = insurance_check_df.loc[(insurance_check_df['PAYER_PLAN_PERIOD_END_DATE']>=insurance_check_df['cohort_start_date'])&(insurance_check_df['PAYER_PLAN_PERIOD_START_DATE'] <= insurance_check_df['cohort_start_date']- pd.Timedelta(days=1095))]['person_id'].unique()\n",
    "\n",
    "print(len(eligible_pids))\n",
    "eligible_pids = list(eligible_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "419630b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63062 5.036313469284196\n"
     ]
    }
   ],
   "source": [
    "df_pop = df_pop.loc[df_pop['person_id'].isin(eligible_pids)]\n",
    "print(len(df_pop), sum(df_pop['sz_flag'])*100/len(df_pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5161344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63062 63062\n"
     ]
    }
   ],
   "source": [
    "print(len(df_pop), len(df_pop['person_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafdf3e",
   "metadata": {},
   "source": [
    "### Get the % of patients (scz and non-scz) who have each psychosis dx as their first dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0def3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "psych_initial_psychosis = psych_initial_psychosis.loc[psych_initial_psychosis['person_id'].isin(df_pop['person_id'])]\n",
    "scz_initial_psychosis = scz_initial_psychosis.loc[scz_initial_psychosis['person_id'].isin(df_pop['person_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52c1abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "psych_init_diagnosis = psych_initial_psychosis.groupby('condition_concept_id').count()['psychosis_diagnosis_date']\n",
    "psych_init_diagnosis.name = 'num_psych_patients'\n",
    "psych_init_diagnosis = pd.DataFrame(psych_init_diagnosis).merge(snomed_to_icd[['snomed_concept_id', 'snomed_concept_name', 'icd_concept_name', 'concept_code']], how = 'left', left_index=True, right_on='snomed_concept_id')\n",
    "\n",
    "scz_init_diagnosis = scz_initial_psychosis.groupby('condition_concept_id').count()['psychosis_diagnosis_date']\n",
    "scz_init_diagnosis.name = 'num_scz_patients'\n",
    "scz_init_diagnosis = pd.DataFrame(scz_init_diagnosis).merge(snomed_to_icd[['snomed_concept_id', 'snomed_concept_name', 'icd_concept_name', 'concept_code']], how = 'left', left_index=True, right_on='snomed_concept_id')\n",
    "\n",
    "initial_diagnoses = psych_init_diagnosis.merge(scz_init_diagnosis[['snomed_concept_id', 'num_scz_patients']], how='outer', left_on = 'snomed_concept_id', right_on='snomed_concept_id')\n",
    "initial_diagnoses.sort_values('concept_code', inplace=True)\n",
    "initial_diagnoses.fillna(0, inplace=True)\n",
    "initial_diagnoses['% SCZ'] = initial_diagnoses['num_scz_patients']/len(df_pop.loc[df_pop['sz_flag']==1])\n",
    "initial_diagnoses['% non-SCZ'] = initial_diagnoses['num_psych_patients']/len(df_pop.loc[df_pop['sz_flag']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d422e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop.to_csv(save_path + 'population.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0d238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b6535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6341a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbab0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
