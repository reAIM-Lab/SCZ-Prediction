{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e9eabde",
   "metadata": {},
   "source": [
    "### This file pulls data from the SQL server and identifies patients within the schizophrenia + psychosis and no-schizophrenia + psychosis cohorts. It then generates CSVs that are subsets of condition_occurrence (conditions), drug_era (medications), visit_occurrence (visits), procedure_occurrence (procedures), and measurement (labs) for all the patients in the schizophrenia + psychosis cohorts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ee059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import gc\n",
    "from scipy.sparse import *\n",
    "import pyarrow as pa\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, TruncatedSVD\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521df606",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = (\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=OMOP.DBMI.COLUMBIA.EDU;'\n",
    "    'DATABASE=cdm_mdcd;'\n",
    "    'TRUSTED_CONNECTION=YES;')\n",
    "\n",
    "conn = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081158c",
   "metadata": {},
   "source": [
    "# Create Cohort\n",
    "1. (In DataGrip) Get all the patients with SCZ/schizoaffective disorder and 7 years of prior observation and save them to the ak4885_schizophrenia_incidence table\n",
    "2. (In DataGrip) Get all patients who have an episode of psychosis (incl. schizophrenia) and 7 years of observation overall -- save this into results as ak4885_psychosis_cohort\n",
    "3. Find all people who are between 10 and 35 years at \"cohort start\" (SCZ diagnosis or observation period end date)\n",
    "4. Eliminate people with SCZ diagnoses from the nosz_conds df AND make sure that the instance of SCZ is not Schizophreniform disorder (444434, 4184004, 4263364) for the SCZ population\n",
    "5. Eliminate all people who's first episode of psychosis is schizophrenia/schizoaffective disorder is their schizophrenia diagnosis\n",
    "6. Get all conditions in 7 years prior to cohort start for both of the above tables\n",
    "7. Combine dataframes (SCZ and No SCZ) and add SCZ \"flag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19eef184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/3172215598.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  psychosis_codes = pd.io.sql.read_sql(all_psychosis_codes_query, conn)\n"
     ]
    }
   ],
   "source": [
    "all_psychosis_codes_query = (\"SELECT c_rel.concept_id as standard_concept_id, c_icd10.concept_code as icd_code, c_rel.concept_name as standard_concept_name, c_icd10.concept_name as icd_concept_name FROM dbo.concept as c_icd10 LEFT JOIN dbo.concept_relationship as rel on rel.concept_id_1 = c_icd10.concept_id \"+\n",
    "                       \"LEFT JOIN dbo.concept as c_rel on rel.concept_id_2 = c_rel.concept_id \"+\n",
    "                         \"WHERE (rel.relationship_id = 'Maps to' AND c_rel.standard_concept = 'S') AND (((c_icd10.concept_code IN ('295', '297', '298', '260.0', '260.1', '296.2', '296.5', '296.6', '296.24', '296.34', '291.3', '291.5', '292.1') OR c_icd10.concept_code LIKE '29[578]%') AND c_icd10.vocabulary_id = 'ICD9CM') \"+\n",
    "                         \"OR ((c_icd10.concept_code LIKE 'F2[023456789]%' OR c_icd10.concept_code LIKE 'F30.[1234]' OR c_icd10.concept_code LIKE 'F31.[01234567]%' OR c_icd10.concept_code IN ('F32.3', 'F33.3', 'F53.1') OR c_icd10.concept_code LIKE 'F1_.15' OR c_icd10.concept_code LIKE 'F__.25' OR c_icd10.concept_code LIKE 'F__.95') AND c_icd10.vocabulary_id = 'ICD10CM'))\")\n",
    "\n",
    "\n",
    "psychosis_codes = pd.io.sql.read_sql(all_psychosis_codes_query, conn)\n",
    "psychosis_codes.to_csv('psychosis_prediction/all_psychosis_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5ad1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/2776791095.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  all_scz_codes = pd.io.sql.read_sql(all_scz_codes_query, conn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Schizophreniform disorder',\n",
       "       'Schizophreniform disorder with good prognostic features',\n",
       "       'Schizophreniform disorder without good prognostic features'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scz_codes_query = (\"SELECT c_new.concept_id as standard_concept_id, c_icd10.concept_code as icd_code, c_new.concept_name as standard_concept_name, c_icd10.concept_name as icd_name FROM dbo.concept as c_icd10 LEFT JOIN dbo.concept_relationship as rel on rel.concept_id_1 = c_icd10.concept_id \"+\n",
    "                \"LEFT JOIN dbo.concept as c_rel on rel.concept_id_2 = c_rel.concept_id \"+\n",
    "                \"LEFT JOIN dbo.concept_ancestor as ca ON ca.ancestor_concept_id = rel.concept_id_2 \"+\n",
    "                \"LEFT JOIN dbo.concept as c_new on c_new.concept_id = ca.descendant_concept_id \" +\n",
    "                \"WHERE (rel.relationship_id = 'Maps to' AND c_new.standard_concept = 'S') \"+\n",
    "                \"AND ((c_icd10.concept_code LIKE '295%' AND c_icd10.vocabulary_id = 'ICD9CM') \"+\n",
    "                \"OR ((c_icd10.concept_code LIKE 'F2[05]%' AND c_icd10.vocabulary_id = 'ICD10CM')))\")\n",
    "\n",
    "all_scz_codes = pd.io.sql.read_sql(all_scz_codes_query, conn)\n",
    "\n",
    "for i in all_scz_codes['icd_code']:\n",
    "    if i not in list(psychosis_codes['icd_code']):\n",
    "        print(i)\n",
    "all_scz_codes.to_csv('psychosis_prediction/all_scz_codes.csv')\n",
    "all_scz_codes.loc[all_scz_codes['standard_concept_id'].isin([444434, 4184004, 4263364])]['standard_concept_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f1b88",
   "metadata": {},
   "source": [
    "### Everyone from original dataset\n",
    "- SCZ: at least one schizophrenia code and 7 years prior observation (non-continuous)\n",
    "- Psychosis: at least one psychosis code and 7 years observation total (non-continuous); remove people also in SCZ cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a204df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/1505819232.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_psychosis_all = pd.io.sql.read_sql(\"SELECT pc.*, year_of_birth, race_concept_id, gender_concept_id FROM results.ak4885_psychosis_cohort as pc LEFT JOIN dbo.person as p ON p.person_id = pc.person_id\", conn)\n",
      "/tmp/ipykernel_124918/1505819232.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_scz_all = pd.io.sql.read_sql(\"SELECT sc.*, year_of_birth, race_concept_id, gender_concept_id FROM results.ak4885_schizophrenia_cohort as sc LEFT JOIN dbo.person as p ON p.person_id = sc.person_id\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519154 62803 10.791690795024374\n"
     ]
    }
   ],
   "source": [
    "df_psychosis_all = pd.io.sql.read_sql(\"SELECT pc.*, year_of_birth, race_concept_id, gender_concept_id FROM results.ak4885_psychosis_cohort as pc LEFT JOIN dbo.person as p ON p.person_id = pc.person_id\", conn)\n",
    "df_scz_all = pd.io.sql.read_sql(\"SELECT sc.*, year_of_birth, race_concept_id, gender_concept_id FROM results.ak4885_schizophrenia_cohort as sc LEFT JOIN dbo.person as p ON p.person_id = sc.person_id\", conn)\n",
    "df_scz_all = df_scz_all.merge(df_psychosis_all[['person_id', 'psychosis_dx_date']], how='left', left_on = 'person_id', right_on = 'person_id')\n",
    "if df_scz_all.isna().sum().sum() > 0:\n",
    "    print('Undefined psychosis diagnosis date after merge')\n",
    "df_psychosis_all = df_psychosis_all.loc[~df_psychosis_all['person_id'].isin(list(df_scz_all['person_id']))]\n",
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194608b5",
   "metadata": {},
   "source": [
    "### Make sure that people in the schizophrenia cohort have at least 1 dx (which is not schizophreniform disorder\n",
    "Ignore the fact that these variables are called \"dx_twice_pids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bf184dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/3648966293.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  all_sz_dx = pd.io.sql.read_sql(all_sz_query, conn)\n"
     ]
    }
   ],
   "source": [
    "# limit schizophrenia cohort to people with 1 diagnoses\n",
    "all_sz_query = (\"SELECT person_id, condition_concept_id, condition_start_date FROM dbo.condition_occurrence WHERE condition_concept_id IN (SELECT c_new.concept_id FROM dbo.concept as c_icd10 LEFT JOIN dbo.concept_relationship as rel on rel.concept_id_1 = c_icd10.concept_id \"+\n",
    "                \"LEFT JOIN dbo.concept as c_rel on rel.concept_id_2 = c_rel.concept_id \"+\n",
    "                \"LEFT JOIN dbo.concept_ancestor as ca ON ca.ancestor_concept_id = rel.concept_id_2 \"+\n",
    "                \"LEFT JOIN dbo.concept as c_new on c_new.concept_id = ca.descendant_concept_id \" +\n",
    "                \"WHERE (rel.relationship_id = 'Maps to' AND c_new.standard_concept = 'S') \"+\n",
    "                \"AND ((c_icd10.concept_code LIKE '295%' AND c_icd10.vocabulary_id = 'ICD9CM') \"+\n",
    "                \"OR ((c_icd10.concept_code LIKE 'F2[05].%' OR c_icd10.concept_code = 'F20.81' AND c_icd10.vocabulary_id = 'ICD10CM'))))\")\n",
    "\n",
    "all_sz_dx = pd.io.sql.read_sql(all_sz_query, conn)\n",
    "\n",
    "# remove schizophreniform disorder as \"acceptable SCZ diagnosis\"\n",
    "all_sz_dx = all_sz_dx.loc[~all_sz_dx['condition_concept_id'].isin([444434, 4184004, 4263364])]\n",
    "\n",
    "dx_twice_pids = all_sz_dx[['person_id','condition_start_date']].drop_duplicates().groupby('person_id').count()['condition_start_date'] >= 1\n",
    "df_scz_all = df_scz_all.loc[df_scz_all['person_id'].isin(list(dx_twice_pids[dx_twice_pids==True].index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61237451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519154 62803 10.791690795024374\n"
     ]
    }
   ],
   "source": [
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1436ed9e",
   "metadata": {},
   "source": [
    "## Make sure that people in the non-schizophrenia cohort have no instances of a schizophrenia diagnosis \n",
    "Do this by getting all conditions for people in the psychosis cohort and then removing anyone with any schizophrenia code at any point in time (they can have schizophrenifrom diagnosis). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4091e68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/3242971202.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  psychosis_conds = pd.io.sql.read_sql(\"SELECT DISTINCT pc.person_id, condition_concept_id, condition_start_date FROM results.ak4885_psychosis_cohort as pc LEFT JOIN dbo.condition_occurrence as co ON co.person_id = pc.person_id\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468650 62803 11.81722560602725\n"
     ]
    }
   ],
   "source": [
    "df_psychosis_all = df_psychosis_all.loc[~(df_psychosis_all['person_id'].isin(list(all_sz_dx['person_id'].unique())))]\n",
    "psychosis_conds = pd.io.sql.read_sql(\"SELECT DISTINCT pc.person_id, condition_concept_id, condition_start_date FROM results.ak4885_psychosis_cohort as pc LEFT JOIN dbo.condition_occurrence as co ON co.person_id = pc.person_id\", conn)\n",
    "\n",
    "scz_codes = all_scz_codes.loc[~all_scz_codes['standard_concept_id'].isin([444434, 4184004, 4263364])]['standard_concept_id']\n",
    "scz_in_psychosis = psychosis_conds.loc[psychosis_conds['condition_concept_id'].isin(scz_codes)]\n",
    "df_psychosis_all = df_psychosis_all.loc[~df_psychosis_all['person_id'].isin(scz_in_psychosis)]\n",
    "\n",
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a66b0e3",
   "metadata": {},
   "source": [
    "### Make sure that people in the schizophrenia cohort have an accurate cohort_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae1bf377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/275060122.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  scz_conds =pd.io.sql.read_sql (\"SELECT DISTINCT sc.person_id, condition_start_date, condition_concept_id FROM results.ak4885_schizophrenia_cohort as sc LEFT JOIN dbo.condition_occurrence as co ON co.person_id = sc.person_id\", conn)\n"
     ]
    }
   ],
   "source": [
    "scz_conds =pd.io.sql.read_sql (\"SELECT DISTINCT sc.person_id, condition_start_date, condition_concept_id FROM results.ak4885_schizophrenia_cohort as sc LEFT JOIN dbo.condition_occurrence as co ON co.person_id = sc.person_id\", conn) \n",
    "scz_in_scz = scz_conds.loc[scz_conds['condition_concept_id'].isin(scz_codes)]\n",
    "scz_in_scz = scz_in_scz.merge(df_scz_all, how='outer', left_on='person_id', right_on='person_id')\n",
    "\n",
    "scz_in_scz['condition_start_date'] = pd.to_datetime(scz_in_scz['condition_start_date'])\n",
    "scz_in_scz['cohort_start_date'] = pd.to_datetime(scz_in_scz['cohort_start_date'])\n",
    "\n",
    "\n",
    "min_scz_start = scz_in_scz.groupby('person_id')['condition_start_date'].min()\n",
    "min_scz_start.name = 'min_scz_start'\n",
    "scz_in_scz = scz_in_scz.merge(min_scz_start, how='left', left_on='person_id', right_index=True)\n",
    "scz_in_scz.loc[scz_in_scz['min_scz_start']<scz_in_scz['cohort_start_date'], 'cohort_start_date'] = scz_in_scz.loc[scz_in_scz['min_scz_start']<scz_in_scz['cohort_start_date'], 'min_scz_start']\n",
    "\n",
    "df_scz_all.drop(['cohort_start_date'], axis=1, inplace=True)\n",
    "df_scz_all = df_scz_all.merge(scz_in_scz[['person_id', 'cohort_start_date']], how='left', left_on = 'person_id', right_on = 'person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd01ff6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468650 62803 11.81722560602725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cohort_definition_id    0\n",
       "person_id               0\n",
       "end_date                0\n",
       "year_of_birth           0\n",
       "race_concept_id         0\n",
       "gender_concept_id       0\n",
       "psychosis_dx_date       0\n",
       "cohort_start_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scz_all.drop_duplicates(inplace=True)\n",
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))\n",
    "df_scz_all.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f67cb2",
   "metadata": {},
   "source": [
    "### Make sure that everyone has an accurate psychosis_dx_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a19fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "psych_in_scz = scz_conds.loc[scz_conds['condition_concept_id'].isin(psychosis_codes['standard_concept_id'])]\n",
    "psych_in_scz = psych_in_scz.merge(df_scz_all, how='outer', left_on='person_id', right_on='person_id')\n",
    "psych_in_scz['psychosis_dx_date'] = pd.to_datetime(psych_in_scz['psychosis_dx_date'], format='mixed')\n",
    "psych_in_scz['condition_start_date'] = pd.to_datetime(psych_in_scz['condition_start_date'])\n",
    "\n",
    "min_psych_start = psych_in_scz.groupby('person_id')['condition_start_date'].min()\n",
    "min_psych_start.name = 'min_psych_start'\n",
    "psych_in_scz = psych_in_scz.merge(min_psych_start, how='left', left_on='person_id', right_index=True)\n",
    "psych_in_scz.loc[psych_in_scz['min_psych_start']<psych_in_scz['psychosis_dx_date'], 'psychosis_dx_date'] = psych_in_scz.loc[psych_in_scz['min_psych_start']<psych_in_scz['psychosis_dx_date'], 'min_psych_start']\n",
    "print(len(psych_in_scz.loc[psych_in_scz['condition_start_date']<psych_in_scz['psychosis_dx_date']]))\n",
    "\n",
    "df_scz_all.drop(['psychosis_dx_date'], axis=1, inplace=True)\n",
    "df_scz_all = df_scz_all.merge(psych_in_scz[['person_id', 'psychosis_dx_date']].drop_duplicates(), how='left', left_on = 'person_id', right_on = 'person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29856cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "psych_in_psych = psychosis_conds.loc[psychosis_conds['condition_concept_id'].isin(psychosis_codes['standard_concept_id'])]\n",
    "psych_in_psych = psych_in_psych.merge(df_psychosis_all, how='outer', left_on='person_id', right_on='person_id')\n",
    "psych_in_psych['psychosis_dx_date'] = pd.to_datetime(psych_in_psych['psychosis_dx_date'], format='mixed')\n",
    "psych_in_psych['condition_start_date'] = pd.to_datetime(psych_in_psych['condition_start_date'])\n",
    "\n",
    "min_psych_psych_start = psych_in_psych.groupby('person_id')['condition_start_date'].min()\n",
    "min_psych_psych_start.name = 'min_psych_psych_start'\n",
    "psych_in_psych = psych_in_psych.merge(min_psych_psych_start, how='left', left_on='person_id', right_index=True)\n",
    "psych_in_psych.loc[psych_in_psych['min_psych_psych_start']<psych_in_psych['psychosis_dx_date'], 'psychosis_dx_date'] = psych_in_psych.loc[psych_in_psych['min_psych_psych_start']<psych_in_psych['psychosis_dx_date'], 'min_psych_psych_start']\n",
    "print(len(psych_in_psych.loc[psych_in_psych['condition_start_date']<psych_in_psych['psychosis_dx_date']]))\n",
    "\n",
    "df_psychosis_all.drop(['psychosis_dx_date'], axis=1, inplace=True)\n",
    "df_psychosis_all = df_psychosis_all.merge(psych_in_psych[['person_id', 'psychosis_dx_date']].drop_duplicates(), how='left', left_on = 'person_id', right_on = 'person_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbbba1",
   "metadata": {},
   "source": [
    "### Ages 10-35 at \"cohort start date\" \n",
    "(end of observation for psychosis patients, first SCZ diagnosis for SCZ patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02600e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202464 16825 7.672523473589647\n"
     ]
    }
   ],
   "source": [
    "df_psychosis_all['end_date'] = pd.to_datetime(df_psychosis_all['end_date'], format = '%Y-%m-%d')\n",
    "df_psychosis_all['year_of_birth'] = pd.to_datetime(df_psychosis_all['year_of_birth'], format = '%Y')\n",
    "df_psychosis_all['age_diagnosis'] = (df_psychosis_all['end_date']-df_psychosis_all['year_of_birth']).dt.days/365\n",
    "\n",
    "df_psychosis_all = df_psychosis_all.loc[df_psychosis_all['age_diagnosis']<=35]\n",
    "df_psychosis_all = df_psychosis_all.loc[df_psychosis_all['age_diagnosis']>=10]\n",
    "\n",
    "df_scz_all['cohort_start_date'] = pd.to_datetime(df_scz_all['cohort_start_date'], format = '%Y-%m-%d')\n",
    "df_scz_all['year_of_birth'] = pd.to_datetime(df_scz_all['year_of_birth'], format = '%Y')\n",
    "df_scz_all['age_diagnosis'] = (df_scz_all['cohort_start_date']-df_scz_all['year_of_birth']).dt.days/365\n",
    "\n",
    "df_scz_all = df_scz_all.loc[df_scz_all['age_diagnosis']<=35]\n",
    "df_scz_all = df_scz_all.loc[df_scz_all['age_diagnosis']>=10]\n",
    "\n",
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70769967",
   "metadata": {},
   "source": [
    "### Now limit to people whos first diagnosis of SCZ is AFTER their first episode of psychosis\n",
    "Restrict to people for whom the cohort start date (schizophrenia diagnosis date) is AFTER the first date of psychosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2156cee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202464 7720 3.672972252883188\n"
     ]
    }
   ],
   "source": [
    "df_scz_all['psychosis_dx_date'] = pd.to_datetime(df_scz_all['psychosis_dx_date'])\n",
    "df_scz_all = df_scz_all.loc[df_scz_all['cohort_start_date']>df_scz_all['psychosis_dx_date']]\n",
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4e0f7",
   "metadata": {},
   "source": [
    "### Loading in temporal conditions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02fc3779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/3610611331.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sz_conds = pd.io.sql.read_sql(sz_conds_query, conn)\n"
     ]
    }
   ],
   "source": [
    "sz_conds_query = (\"SELECT sz.*, co.condition_start_date, co.condition_concept_id, c.concept_name \"+\n",
    "                  \"FROM cdm_mdcd.results.ak4885_schizophrenia_cohort as sz \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.condition_occurrence as co on co.person_id = sz.person_id \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.concept as c on c.concept_id = co.condition_concept_id \"+\n",
    "                  \"WHERE condition_concept_id > 0\")\n",
    "sz_conds = pd.io.sql.read_sql(sz_conds_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "633ca93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/705663869.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  for chunk in pd.io.sql.read_sql(nosz_conds_query, conn, chunksize=500000):\n"
     ]
    }
   ],
   "source": [
    "nosz_conds_query = (\"SELECT pc.*, co.condition_start_date, co.condition_concept_id, c.concept_name \"+\n",
    "                  \"FROM cdm_mdcd.results.ak4885_psychosis_cohort as pc \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.condition_occurrence as co on co.person_id = pc.person_id \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.concept as c on c.concept_id = co.condition_concept_id \"+\n",
    "                  \"WHERE condition_concept_id > 0\")\n",
    "\n",
    "list_chunks = []\n",
    "for chunk in pd.io.sql.read_sql(nosz_conds_query, conn, chunksize=500000):\n",
    "    list_chunks.append(chunk.loc[chunk['person_id'].isin(df_psychosis_all['person_id'])])\n",
    "nosz_conds = pd.concat(list_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f2765b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del list_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f0fb37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67290605\n",
      "67290605\n",
      "68875912\n",
      "7669379\n"
     ]
    }
   ],
   "source": [
    "print(len(nosz_conds))\n",
    "nosz_conds = nosz_conds.loc[nosz_conds['person_id'].isin(list(df_psychosis_all['person_id']))]\n",
    "print(len(nosz_conds))\n",
    "\n",
    "print(len(sz_conds))\n",
    "sz_conds = sz_conds.loc[sz_conds['person_id'].isin(list(df_scz_all['person_id']))]\n",
    "print(len(sz_conds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b4db51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nosz_conds['cohort_start_date'] = nosz_conds['end_date']\n",
    "sz_conds = sz_conds.merge(df_scz_all[['person_id', 'psychosis_dx_date']], how='left', left_on = 'person_id', right_on = 'person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d921f18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74959984\n",
      "Index(['cohort_definition_id', 'person_id', 'cohort_start_date', 'end_date',\n",
      "       'condition_start_date', 'condition_concept_id', 'concept_name',\n",
      "       'psychosis_dx_date', 'sz_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sz_conds['sz_flag'] = 1\n",
    "nosz_conds['sz_flag'] = 0\n",
    "all_conds = pd.concat([sz_conds, nosz_conds])\n",
    "print(len(all_conds))\n",
    "print(all_conds.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da738b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del sz_conds\n",
    "del nosz_conds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01b6fc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210184 3.672972252883188\n"
     ]
    }
   ],
   "source": [
    "df_psychosis_all['sz_flag'] = 0\n",
    "df_scz_all['sz_flag'] = 1\n",
    "\n",
    "df_psychosis_all['cohort_start_date'] = df_psychosis_all['end_date']\n",
    "\n",
    "df_pop = pd.concat([df_psychosis_all, df_scz_all])\n",
    "print(len(df_pop), sum(df_pop['sz_flag'])*100/len(df_pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61af4c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conds.isna().sum().sum(), df_pop.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066efb5b",
   "metadata": {},
   "source": [
    "# Constrict cohort based on continuous care\n",
    "### First drop instances of conditions where the condition concept id is not defined\n",
    "\n",
    "\n",
    "### To ensure that there is at least 1 service contact per year\n",
    "\n",
    "Calculate the differences between consecutive condition occurrences for each patient -- do this by making sure that:\n",
    "1. there are at least 7 unique dates that there is a visit \n",
    "2. there's at least one visit > 6 years before diagnosis\n",
    "3. the max difference between consecutive dates is 1 year (inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f818c4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done datetime conversions\n",
      "done getting at least 7 unique dates for visits\n",
      "done w/ earliest visit prior to 6 years pre-cohort start\n",
      "done grouping for 1 year between conditions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 202573/202573 [01:22<00:00, 2449.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108322\n"
     ]
    }
   ],
   "source": [
    "# drop undefined conditions\n",
    "all_conds['condition_start_date'] = pd.to_datetime(all_conds['condition_start_date'], format = '%Y-%m-%d')\n",
    "all_conds['cohort_start_date'] = pd.to_datetime(all_conds['cohort_start_date'], format = '%Y-%m-%d')\n",
    "\n",
    "conds_dates = all_conds[['person_id', 'condition_start_date', 'cohort_start_date']].drop_duplicates()\n",
    "print('done datetime conversions')\n",
    "\n",
    "# at least 7 unique dates for visits\n",
    "conds_patients = conds_dates.groupby('person_id').count()\n",
    "yearly_service_pids = list(conds_patients.loc[conds_patients['condition_start_date'] >= 7].index)\n",
    "print('done getting at least 7 unique dates for visits')\n",
    "\n",
    "# at least 1 visit > 6 years before diagnosis\n",
    "conds_dates = conds_dates.loc[conds_dates['person_id'].isin(yearly_service_pids)]\n",
    "yearly_service_pids = list(conds_dates.loc[(conds_dates['cohort_start_date']-conds_dates['condition_start_date']).dt.days > 2190]['person_id'].unique())\n",
    "print('done w/ earliest visit prior to 6 years pre-cohort start')\n",
    "\n",
    "# maximum of 1 year between conditions\n",
    "conds_dates = conds_dates.loc[conds_dates['person_id'].isin(yearly_service_pids)]\n",
    "conds_dates_grouped = conds_dates.groupby(['person_id'])['condition_start_date'].apply(np.hstack)\n",
    "conds_dates_arr = conds_dates_grouped.reset_index().values\n",
    "print('done grouping for 1 year between conditions')\n",
    "\n",
    "yearly_service_pids = []\n",
    "for ind in tqdm(range(0,len(conds_dates_arr))):\n",
    "    if len(conds_dates_arr[ind,1])>1:\n",
    "        conds_dates_arr[ind,1].sort()\n",
    "        if(max(np.diff(conds_dates_arr[ind,1])).days<=365):\n",
    "            yearly_service_pids.append(conds_dates_arr[ind,0])\n",
    "print(len(yearly_service_pids))\n",
    "\n",
    "pd.DataFrame(yearly_service_pids).to_csv('psychosis_prediction/yearly_service_pids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e03bba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102820 5502 5.0793006037554695\n"
     ]
    }
   ],
   "source": [
    "df_psychosis_all = df_psychosis_all.loc[df_psychosis_all['person_id'].isin(yearly_service_pids)]\n",
    "df_scz_all = df_scz_all.loc[df_scz_all['person_id'].isin(yearly_service_pids)]\n",
    "\n",
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0cea687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108322\n"
     ]
    }
   ],
   "source": [
    "df_pop = df_pop.loc[df_pop['person_id'].isin(yearly_service_pids)]\n",
    "print(len(df_pop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7682fc",
   "metadata": {},
   "source": [
    "## Maximum of 45 days with no insurance coverage\n",
    "- Get insurance information from all people with at least 7 years observation and then limit to only the people in with at least 1 service visit per year\n",
    "- Combine all of the overlapping payer periods, with a grace period of 45 days between coverage periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3071942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/3016223025.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  insurance_df = pd.io.sql.read_sql(insurance_query, conn)\n"
     ]
    }
   ],
   "source": [
    "insurance_query = (\"SELECT ppp.PERSON_ID, ppp.PAYER_PLAN_PERIOD_START_DATE, ppp.PAYER_PLAN_PERIOD_END_DATE, ppp.PAYER_SOURCE_VALUE \"+\n",
    "                   \"FROM dbo.PAYER_PLAN_PERIOD as ppp LEFT JOIN dbo.OBSERVATION_PERIOD as op ON op.person_id = ppp.PERSON_ID \"+\n",
    "                   \"WHERE DATEDIFF(day, OBSERVATION_PERIOD_START_DATE, OBSERVATION_PERIOD_END_DATE) > 2555\")\n",
    "insurance_df = pd.io.sql.read_sql(insurance_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8aea5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391173"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df = insurance_df.loc[insurance_df['PERSON_ID'].isin(yearly_service_pids)]\n",
    "len(insurance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "375a8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df['PAYER_PLAN_PERIOD_START_DATE'] =  pd.to_datetime(insurance_df['PAYER_PLAN_PERIOD_START_DATE'], format='%Y-%m-%d')\n",
    "insurance_df['PAYER_PLAN_PERIOD_END_DATE'] =  pd.to_datetime(insurance_df['PAYER_PLAN_PERIOD_END_DATE'], format='%Y-%m-%d')\n",
    "\n",
    "# https://stackoverflow.com/questions/68714898/merge-consecutive-and-overlapping-date-ranges\n",
    "\n",
    "merged_insurance_df = insurance_df.groupby([\"PERSON_ID\"], as_index=False).apply(\n",
    "    lambda d: d.sort_values([\"PAYER_PLAN_PERIOD_END_DATE\", \"PAYER_PLAN_PERIOD_START_DATE\"])\n",
    "    .assign(\n",
    "        grp=lambda d: (\n",
    "            ~(d[\"PAYER_PLAN_PERIOD_START_DATE\"] <= (d[\"PAYER_PLAN_PERIOD_END_DATE\"].shift() + pd.Timedelta(days=45)))\n",
    "        ).cumsum()\n",
    "    )\n",
    "    .groupby([\"PERSON_ID\", \"grp\"], as_index=False)\n",
    "    .agg({\"PAYER_PLAN_PERIOD_START_DATE\": \"min\", \"PAYER_PLAN_PERIOD_END_DATE\": \"max\"})\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df246664",
   "metadata": {},
   "source": [
    "Now that we have adjusted for the combined insurance periods with a 45-day grace period, we want to make sure that it extends from 7 years pre-diagnosis to the date of diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63a53e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104391\n"
     ]
    }
   ],
   "source": [
    "df_pop['cohort_start_date'] =  pd.to_datetime(df_pop['cohort_start_date'], format='%Y-%m-%d')\n",
    "\n",
    "insurance_check_df = df_pop.merge(merged_insurance_df, how = 'left', left_on = 'person_id', right_on = 'PERSON_ID')\n",
    "eligible_pids = insurance_check_df.loc[(insurance_check_df['PAYER_PLAN_PERIOD_END_DATE']>=insurance_check_df['cohort_start_date'])&(insurance_check_df['PAYER_PLAN_PERIOD_START_DATE'] <= insurance_check_df['cohort_start_date']- pd.Timedelta(days=2555))]['person_id'].unique()\n",
    "\n",
    "print(len(eligible_pids))\n",
    "eligible_pids = list(eligible_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fdc8e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102568 1823 1.7463191271278176\n"
     ]
    }
   ],
   "source": [
    "df_psychosis_all = df_psychosis_all.loc[df_psychosis_all['person_id'].isin(eligible_pids)]\n",
    "df_scz_all = df_scz_all.loc[df_scz_all['person_id'].isin(eligible_pids)]\n",
    "\n",
    "print(len(df_psychosis_all), len(df_scz_all), len(df_scz_all)*100/(len(df_scz_all)+len(df_psychosis_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ddc4d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104391 1.7463191271278176\n"
     ]
    }
   ],
   "source": [
    "df_psychosis_all['sz_flag'] = 0\n",
    "df_scz_all['sz_flag'] = 1\n",
    "df_pop = pd.concat([df_psychosis_all, df_scz_all])\n",
    "print(len(df_pop), sum(df_pop['sz_flag'])*100/len(df_pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cd29659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop.to_csv('psychosis_prediction/population.csv', index=False)\n",
    "pd.DataFrame(eligible_pids).to_csv('psychosis_prediction/insurance_pids.csv', index=False)\n",
    "pd.DataFrame(yearly_service_pids).to_csv('psychosis_prediction/yearly_service_pids.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994b63a2",
   "metadata": {},
   "source": [
    "According to the NIMH (https://www.nimh.nih.gov/health/statistics/schizophrenia), 0.66% is within range (0.33% to 0.75%) for prevalence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57a89599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patients: 104391\n",
      "% Patients with Schizophrenia: 1.7463191271278176\n"
     ]
    }
   ],
   "source": [
    "print('Total patients:',len(df_pop))\n",
    "print('% Patients with Schizophrenia:',100*sum(df_pop['sz_flag'])/len(df_pop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56eb6b",
   "metadata": {},
   "source": [
    "### Save all_conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f2e0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conds = all_conds.loc[all_conds['person_id'].isin(eligible_pids)]\n",
    "all_conds.drop(['cohort_start_date'], axis=1, inplace=True)\n",
    "all_conds = all_conds.merge(df_pop[['person_id', 'cohort_start_date']], how='left', left_on = 'person_id', right_on = 'person_id')\n",
    "all_conds.to_csv('psychosis_prediction/temporal_conditions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91afe2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50648725\n"
     ]
    }
   ],
   "source": [
    "print(len(all_conds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e803dc9",
   "metadata": {},
   "source": [
    "# Load in and Save other Data (Temporal)\n",
    "## Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cde8b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = pd.read_csv('psychosis_prediction/population.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "663bb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/1054108358.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sz_meds = pd.io.sql.read_sql(sz_meds_query, conn)\n"
     ]
    }
   ],
   "source": [
    "sz_meds_query = (\"SELECT sz.*, drug_concept_id, drug_era_start_date, drug_era_end_date, drug_exposure_count, gap_days \"+ \n",
    "                 \"FROM cdm_mdcd.results.ak4885_schizophrenia_cohort as sz \"+\n",
    "                   \"LEFT JOIN cdm_mdcd.dbo.drug_era on drug_era.person_id = sz.person_id\")\n",
    "\n",
    "\n",
    "sz_meds = pd.io.sql.read_sql(sz_meds_query, conn)\n",
    "sz_meds.columns = sz_meds.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3ba630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/3704060413.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  for chunk in pd.io.sql.read_sql(nosz_meds_query, conn, chunksize=1000000):\n"
     ]
    }
   ],
   "source": [
    "nosz_meds_query = (\"SELECT pc.*, drug_concept_id, drug_era_start_date, drug_era_end_date, drug_exposure_count, gap_days \"+ \n",
    "                 \"FROM cdm_mdcd.results.ak4885_psychosis_cohort as pc \"+\n",
    "                   \"LEFT JOIN cdm_mdcd.dbo.drug_era on drug_era.person_id = pc.person_id\")\n",
    "list_chunks = []\n",
    "for chunk in pd.io.sql.read_sql(nosz_meds_query, conn, chunksize=1000000):\n",
    "    list_chunks.append(chunk.loc[chunk['person_id'].isin(df_pop['person_id'])])\n",
    "nosz_meds = pd.concat(list_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0498a968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del list_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00e8a341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "sz_meds = sz_meds.merge(df_pop[['person_id', 'psychosis_dx_date']], how='left', left_on = 'person_id', right_on='person_id')\n",
    "nosz_meds['cohort_start_date'] = nosz_meds['end_date']\n",
    "print(set(sz_meds.columns) == set(nosz_meds.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f30fc424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_meds = pd.concat([sz_meds, nosz_meds])\n",
    "\n",
    "del sz_meds\n",
    "del nosz_meds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f0faeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8360779\n",
      "104124\n"
     ]
    }
   ],
   "source": [
    "all_meds = all_meds.loc[all_meds['person_id'].isin(list(df_pop['person_id']))]\n",
    "all_meds.drop(['cohort_start_date'], axis=1, inplace=True)\n",
    "all_meds = all_meds.merge(df_pop[['person_id', 'cohort_start_date']], how='left', left_on = 'person_id', right_on = 'person_id')\n",
    "all_meds.dropna(inplace=True)\n",
    "print(len(all_meds))\n",
    "print(len(all_meds['person_id'].unique()))\n",
    "all_meds.to_csv('psychosis_prediction/temporal_medications.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b480d64",
   "metadata": {},
   "source": [
    "## Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48b2ab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/3491983155.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sz_visits = pd.io.sql.read_sql(sz_visits_query, conn)\n"
     ]
    }
   ],
   "source": [
    "sz_visits_query = (\"SELECT sz.*, visit_occurrence_id, visit_concept_id, visit_start_date, visit_end_date, visit_type_concept_id \" +\n",
    "                   \"FROM cdm_mdcd.results.ak4885_schizophrenia_cohort as sz \"+\n",
    "                   \"LEFT JOIN cdm_mdcd.dbo.visit_occurrence as v on v.person_id = sz.person_id\")\n",
    "\n",
    "sz_visits = pd.io.sql.read_sql(sz_visits_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5e2e6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/2252992099.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  for chunk in pd.io.sql.read_sql(nosz_visits_query, conn, chunksize=1000000):\n"
     ]
    }
   ],
   "source": [
    "nosz_visits_query = (\"SELECT pc.*, visit_occurrence_id, visit_concept_id, visit_start_date, visit_end_date, visit_type_concept_id \" +\n",
    "                   \"FROM cdm_mdcd.results.ak4885_psychosis_cohort as pc \"+\n",
    "                   \"LEFT JOIN cdm_mdcd.dbo.visit_occurrence as v on v.person_id = pc.person_id\")\n",
    "\n",
    "list_chunks = []\n",
    "for chunk in pd.io.sql.read_sql(nosz_visits_query, conn, chunksize=1000000):\n",
    "    list_chunks.append(chunk.loc[chunk['person_id'].isin(df_pop['person_id'])])\n",
    "nosz_visits = pd.concat(list_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68b207a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del list_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a97b56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz_visits = sz_visits.merge(df_pop[['person_id', 'psychosis_dx_date']], how='left', left_on = 'person_id', right_on='person_id')\n",
    "nosz_visits['cohort_start_date'] = nosz_visits['end_date']\n",
    "\n",
    "all_visits = pd.concat([sz_visits, nosz_visits])\n",
    "\n",
    "del sz_visits\n",
    "del nosz_visits\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b2490c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38036085\n",
      "104391\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_pop = pd.read_csv('psychosis_prediction/population.csv')\n",
    "all_visits = all_visits.loc[all_visits['person_id'].isin(list(df_pop['person_id']))]\n",
    "all_visits.drop(['cohort_start_date'], axis=1, inplace=True)\n",
    "all_visits = all_visits.merge(df_pop[['person_id', 'cohort_start_date']], how='left', left_on = 'person_id', right_on = 'person_id')\n",
    "\n",
    "print(len(all_visits))\n",
    "print(len(all_visits['person_id'].unique()))\n",
    "all_visits.to_csv('psychosis_prediction/temporal_visits.csv')\n",
    "print(all_visits.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3094de16",
   "metadata": {},
   "source": [
    "## Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe77b967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/2562366103.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sz_procedures = pd.io.sql.read_sql(sz_procedures_query, conn)\n"
     ]
    }
   ],
   "source": [
    "sz_procedures_query = (\"SELECT sz.*, procedure_date, procedure_concept_id, c.concept_name \"+\n",
    "                  \"FROM cdm_mdcd.results.ak4885_schizophrenia_cohort as sz \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.procedure_occurrence as po on po.person_id = sz.person_id \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.concept as c on c.concept_id = po.procedure_concept_id\")\n",
    "\n",
    "sz_procedures = pd.io.sql.read_sql(sz_procedures_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49bd113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/4110452677.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  for chunk in pd.io.sql.read_sql(nosz_procedures_query, conn, chunksize=1000000):\n"
     ]
    }
   ],
   "source": [
    "nosz_procedures_query = (\"SELECT pc.*, procedure_date, procedure_concept_id, c.concept_name \"+\n",
    "                  \"FROM cdm_mdcd.results.ak4885_psychosis_cohort as pc \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.procedure_occurrence as po on po.person_id = pc.person_id \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.concept as c on c.concept_id = po.procedure_concept_id\")\n",
    "\n",
    "list_chunks = []\n",
    "for chunk in pd.io.sql.read_sql(nosz_procedures_query, conn, chunksize=1000000):\n",
    "    list_chunks.append(chunk.loc[chunk['person_id'].isin(df_pop['person_id'])])\n",
    "nosz_procedures = pd.concat(list_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7dbed9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del list_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57f7a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_procedures = sz_procedures.merge(df_pop[['person_id', 'psychosis_dx_date']], how='left', left_on = 'person_id', right_on='person_id')\n",
    "nosz_procedures['cohort_start_date'] = nosz_procedures['end_date']\n",
    "\n",
    "all_procedures = pd.concat([sz_procedures, nosz_procedures])\n",
    "all_procedures = all_procedures.loc[all_procedures['procedure_concept_id']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "861ab915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del sz_procedures\n",
    "del nosz_procedures\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b527f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29215443\n",
      "104385\n"
     ]
    }
   ],
   "source": [
    "df_pop = pd.read_csv('psychosis_prediction/population.csv')\n",
    "all_procedures = all_procedures.loc[all_procedures['person_id'].isin(list(df_pop['person_id']))]\n",
    "all_procedures.dropna(inplace=True)\n",
    "all_procedures.drop(['cohort_start_date'], axis=1, inplace=True)\n",
    "all_procedures = all_procedures.merge(df_pop[['person_id', 'cohort_start_date']], how='left', left_on = 'person_id', right_on = 'person_id')\n",
    "print(len(all_procedures))\n",
    "print(len(all_procedures['person_id'].unique()))\n",
    "all_procedures.to_csv('psychosis_prediction/temporal_procedures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9bc4e",
   "metadata": {},
   "source": [
    "## Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc3ae545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/387976281.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sz_labs = pd.io.sql.read_sql(sz_measurement_query, conn)\n"
     ]
    }
   ],
   "source": [
    "sz_measurement_query = (\"SELECT sz.*, measurement_date, measurement_concept_id, c.concept_name \"+\n",
    "                  \"FROM cdm_mdcd.results.ak4885_schizophrenia_cohort as sz \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.measurement as m on m.person_id = sz.person_id \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.concept as c on c.concept_id = m.measurement_concept_id\")\n",
    "\n",
    "sz_labs = pd.io.sql.read_sql(sz_measurement_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11769975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124918/2581047563.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  for chunk in pd.io.sql.read_sql(nosz_measurements_query, conn, chunksize=1000000):\n"
     ]
    }
   ],
   "source": [
    "nosz_measurements_query = (\"SELECT pc.*, measurement_date, measurement_concept_id, c.concept_name \"+\n",
    "                  \"FROM cdm_mdcd.results.ak4885_psychosis_cohort as pc \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.measurement as m on m.person_id = pc.person_id \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.concept as c on c.concept_id = m.measurement_concept_id\")\n",
    "list_chunks = []\n",
    "for chunk in pd.io.sql.read_sql(nosz_measurements_query, conn, chunksize=1000000):\n",
    "    list_chunks.append(chunk.loc[chunk['person_id'].isin(df_pop['person_id'])])\n",
    "nosz_labs = pd.concat(list_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7cbae113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del list_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "386c72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_labs = sz_labs.merge(df_pop[['person_id', 'psychosis_dx_date']], how='left', left_on = 'person_id', right_on='person_id')\n",
    "nosz_labs['cohort_start_date'] = nosz_labs['end_date']\n",
    "\n",
    "all_labs = pd.concat([sz_labs, nosz_labs])\n",
    "all_labs = all_labs.loc[all_labs['measurement_concept_id']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "424ae708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del sz_labs\n",
    "del nosz_labs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f61eb8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8782674\n",
      "103620\n"
     ]
    }
   ],
   "source": [
    "df_pop = pd.read_csv('psychosis_prediction/population.csv')\n",
    "all_labs = all_labs.loc[all_labs['person_id'].isin(list(df_pop['person_id']))]\n",
    "all_labs.dropna(inplace=True)\n",
    "all_labs.drop(['cohort_start_date'], axis=1, inplace=True)\n",
    "all_labs = all_labs.merge(df_pop[['person_id', 'cohort_start_date']], how='left', left_on = 'person_id', right_on = 'person_id')\n",
    "print(len(all_labs))\n",
    "print(len(all_labs['person_id'].unique()))\n",
    "all_labs.to_csv('psychosis_prediction/temporal_labs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef9c36",
   "metadata": {},
   "source": [
    "## Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb16efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_conds_query = (\"SELECT sz.*, condition_start_date, condition_concept_id, c.concept_name \"+\n",
    "                  \"FROM cdm_mdcd.results.ak4885_schizophrenia_cohort as sz \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.condition_occurrence as co on co.person_id = sz.person_id \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.concept as c on c.concept_id = co.condition_concept_id \"+\n",
    "                  \"WHERE condition_concept_id > 0\")\n",
    "\n",
    "sz_conds = pd.io.sql.read_sql(sz_conds_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96414f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nosz_conds_query = (\"SELECT pc.*, condition_start_date, condition_concept_id, c.concept_name \"+\n",
    "                  \"FROM cdm_mdcd.results.ak4885_psychosis_cohort as pc \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.condition_occurrence as co on co.person_id = pc.person_id \"+\n",
    "                  \"LEFT JOIN cdm_mdcd.dbo.concept as c on c.concept_id = co.condition_concept_id \"+\n",
    "                  \"WHERE condition_concept_id > 0\")\n",
    "list_chunks = []\n",
    "for chunk in pd.io.sql.read_sql(nosz_conds_query, conn, chunksize=1000000):\n",
    "    list_chunks.append(chunk)\n",
    "nosz_conds = pd.concat(list_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae202963",
   "metadata": {},
   "outputs": [],
   "source": [
    "del list_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd597517",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_conds = sz_conds.merge(df_pop[['person_id', 'psychosis_dx_date']], how='left', left_on = 'person_id', right_on='person_id')\n",
    "nosz_conds['cohort_start_date'] = nosz_conds['end_date']\n",
    "\n",
    "all_conds = pd.concat([sz_conds, nosz_conds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafb1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sz_conds\n",
    "del nosz_conds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3339135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59104819\n",
      "125026\n"
     ]
    }
   ],
   "source": [
    "df_pop = pd.read_csv('psychosis_prediction/population.csv')\n",
    "all_conds = all_conds.loc[all_conds['person_id'].isin(list(df_pop['person_id']))]\n",
    "all_conds.drop(['cohort_start_date'], axis=1, inplace=True)\n",
    "all_conds = all_conds.merge(df_pop[['person_id', 'cohort_start_date']], how='left', left_on = 'person_id', right_on = 'person_id')\n",
    "\n",
    "print(len(all_conds))\n",
    "print(len(all_conds['person_id'].unique()))\n",
    "all_conds.to_csv('psychosis_prediction/temporal_conditions.csv')\n",
    "print(all_conds.isna().sum().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
