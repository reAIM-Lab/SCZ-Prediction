{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10847796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import gc\n",
    "from scipy.sparse import *\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pickle \n",
    "import random\n",
    "import math\n",
    "from joblib import dump, load\n",
    "import matplotlib\n",
    "\n",
    "from models import *\n",
    "sys.path.append('../utils')\n",
    "from dl_eval_utils import *\n",
    "from eval_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a9e69",
   "metadata": {},
   "source": [
    "# Choose best model based on hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"MODEL PATH\"\n",
    "df_perf_lstm = pd.read_csv(model_path + 'MDCD_snomed_11_15_lstm_gridsearch.csv')\n",
    "df_perf_trans = pd.read_csv(model_path + 'MDCD_snomed_11_15_transformer_gridsearch.csv')\n",
    "df_perf_lstm.sort_values('AUPRC', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57896c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_trans.sort_values('AUPRC', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6692c6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 256, 'dim_feedforward': 128, 'num_layers': 2, 'weights': tensor([1, 1], device='cuda:0'), 'emb_first': True, 'dropout': 0.3, 'learning_rate': 0.0001, 'weight_decay': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(df_perf_trans.iloc[109]['config'])\n",
    "# transformer_dimFF128_hs256_nl2_lr0.0001_dropout0.3_wd0.001_weights1_EmbPE.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ad956",
   "metadata": {},
   "source": [
    "# Get overall model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1548ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3727008/1049533622.py:7: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_pop = pd.read_csv(raw_path+'population.csv')\n",
      "/usr/lib/python3/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "path = 'PATH'\n",
    "raw_path = path + 'RAW DATA PATH'\n",
    "int_path = path + 'INTERMEDIATE PATH'\n",
    "result_data_path = path + 'RESULTS PATH'\n",
    "\n",
    "\n",
    "df_pop = pd.read_csv(raw_path+'population.csv')\n",
    "\n",
    "# X_mean = torch.load(int_path + 'MDCD_10_30_grud_means.pt')\n",
    "with open(int_path + \"MDCD_11_15_dl_colnames_snomed\", \"rb\") as fp:   # Unpickling\n",
    "    save_cols = pickle.load(fp)\n",
    "    \n",
    "# testing_clf = LSTMModel(input_size = len(save_cols), hidden_size=128, embedding_size = 1024, num_layers=2, dropout = 0.1, output_size=1)\n",
    "testing_clf = TransformerModelEmbPE(hidden_size=256, dim_feedforward=128, num_layers=2, num_heads=4, dropout=0.3, n_features = len(save_cols))\n",
    "# testing_clf = GRUD(len(save_cols), len(save_cols), len(save_cols), X_mean, output_last = True)\n",
    "testing_clf.load_state_dict(torch.load(model_path + 'transformer_dimFF128_hs256_nl2_lr0.0001_dropout0.3_wd0.001_weights1_EmbPE.pt'))\n",
    "testing_clf.eval()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "testing_clf.to(device)\n",
    "\n",
    "val_loader = torch.load(int_path + 'MDCD_11_15_dl_snomed_val_loader_unshuffled.pth')\n",
    "test_loader = torch.load(int_path + 'MDCD_11_15_dl_snomed_test_loader_unshuffled.pth')\n",
    "\n",
    "# Define metrics of interest\n",
    "metric_functions = {\n",
    "    'AUROC': roc_auc_score,\n",
    "    'AUPRC': average_precision_score,\n",
    "    'Sensitivity': sensitivity,\n",
    "    'Specificity': specificity,\n",
    "    'PPV': ppv_score}\n",
    "binary_funcs = ['Sensitivity', 'Specificity', 'PPV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8071ceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff Probability: 0.05039993\n"
     ]
    }
   ],
   "source": [
    "# Get cutoff\n",
    "val_modeloutput = ModelOutput(val_loader, testing_clf, 31)\n",
    "y_valtrue, y_valpred = val_modeloutput.get_output_vals()\n",
    "val_labels = pd.DataFrame(np.asarray([y_valtrue, y_valpred]).T, columns = ['sz_flag', 'pred_prob'])\n",
    "cutoff_prob = val_modeloutput.get_cutoff_prob(y_valtrue, y_valpred, stored_data_path = model_path, save_filename = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8d3e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 300/300 [00:11<00:00, 25.31it/s]\n",
      "100%|████████████████████████████████████████████████████| 300/300 [00:22<00:00, 13.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get test performance\n",
    "test_modeloutput = ModelOutput(test_loader, testing_clf, 31)\n",
    "y_testtrue, y_testpred = test_modeloutput.get_output_vals()\n",
    "test_labels = pd.DataFrame(np.asarray([y_testtrue, y_testpred]).T, columns = ['sz_flag', 'pred_prob'])\n",
    "\n",
    "table2 = pd.DataFrame(columns = ['AUROC', 'AUPRC', 'Sensitivity', 'Specificity', 'PPV'])\n",
    "table2 = create_table2_row(table2, val_labels, 'Validation', 'pred_prob', cutoff_prob, metric_functions, binary_funcs)\n",
    "table2 = create_table2_row(table2, test_labels, 'Test', 'pred_prob', cutoff_prob, metric_functions, binary_funcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9f7b3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>PPV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>0.805 (0.786, 0.822)</td>\n",
       "      <td>0.339 (0.301, 0.376)</td>\n",
       "      <td>0.757 (0.723, 0.788)</td>\n",
       "      <td>0.725 (0.713, 0.735)</td>\n",
       "      <td>0.201 (0.184, 0.218)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.796 (0.78, 0.809)</td>\n",
       "      <td>0.312 (0.286, 0.338)</td>\n",
       "      <td>0.727 (0.697, 0.753)</td>\n",
       "      <td>0.714 (0.707, 0.721)</td>\n",
       "      <td>0.188 (0.176, 0.2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AUROC                 AUPRC           Sensitivity  \\\n",
       "Validation  0.805 (0.786, 0.822)  0.339 (0.301, 0.376)  0.757 (0.723, 0.788)   \n",
       "Test         0.796 (0.78, 0.809)  0.312 (0.286, 0.338)  0.727 (0.697, 0.753)   \n",
       "\n",
       "                     Specificity                   PPV  \n",
       "Validation  0.725 (0.713, 0.735)  0.201 (0.184, 0.218)  \n",
       "Test        0.714 (0.707, 0.721)    0.188 (0.176, 0.2)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53776450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0315e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
