{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18bbd1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import gc\n",
    "from scipy.sparse import csr_matrix\n",
    "import pyarrow as pa\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d31c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = (\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=OMOP.DBMI.COLUMBIA.EDU;'\n",
    "    'DATABASE=cdm_mdcd;'\n",
    "    'TRUSTED_CONNECTION=YES;')\n",
    "\n",
    "conn = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b586d79",
   "metadata": {},
   "source": [
    "# Combine data from various sources to create data object for the model\n",
    "- Load in df_pop and subset to the patients you want\n",
    "    - num_days_prediction is the right censor (cutoff time)\n",
    "    - can also choose here to downsample negative patients\n",
    "- Read in each of the individual dataframes and limit to patients that are consistent with df_pop and num_days_prediction\n",
    "- Process dataframes so I only keep the columns: person_id, days until cohort start, and concept_id (and rename them)\n",
    "    - Also remove rare events (<1% of population)\n",
    "    - For medications get separate entries for each day that the person was on the medication\n",
    "    - For visits, get separate entries (and a separate feature) for number of \"overnights\" for inpatient and ED visits\n",
    "- Concatenate the following dataframes: all_visits, all_conds, all_meds, all_procedures, all_labs, los_df (overnights, see above) and group individual days into chunks of times\n",
    "- Create the sparse dataframe using pandas grouper\n",
    "- Turn the sparse dataframe into a dense dataframe with all indices (including rows that are completely empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6f95444",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days_prediction = 90\n",
    "df_pop = pd.read_csv('psychosis_prediction/population.csv')\n",
    "df_pop['psychosis_diagnosis_date'] = pd.to_datetime(df_pop['psychosis_diagnosis_date'], format=\"mixed\")\n",
    "df_pop['cohort_start_date'] = pd.to_datetime(df_pop['cohort_start_date'])\n",
    "df_pop = df_pop.loc[(df_pop['cohort_start_date']-df_pop['psychosis_diagnosis_date']).dt.days >= num_days_prediction]\n",
    "\n",
    "# limit the negative class using a random subsample for class balance\n",
    "negative_pids = df_pop.loc[df_pop['sz_flag']==0, 'person_id']\n",
    "negative_subsample = np.random.randint(0,len(negative_pids),8000)\n",
    "df_pop = df_pop.loc[(df_pop['person_id'].isin(negative_pids.iloc[negative_subsample])) | (df_pop['sz_flag']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71b7ba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_399374/1439883620.py:11: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_conds = pd.read_csv('psychosis_prediction/temporal_conditions.csv')\n",
      "/tmp/ipykernel_399374/1439883620.py:27: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_labs = pd.read_csv('psychosis_prediction/temporal_labs.csv')\n"
     ]
    }
   ],
   "source": [
    "# read in the data from each of the individual domains/tables\n",
    "all_visits = pd.read_csv('psychosis_prediction/temporal_visits.csv')\n",
    "all_visits = all_visits.loc[all_visits['person_id'].isin(df_pop['person_id'])]\n",
    "all_visits['cohort_start_date'] = pd.to_datetime(all_visits['cohort_start_date'])\n",
    "all_visits['visit_start_date'] = pd.to_datetime(all_visits['visit_start_date'])\n",
    "all_visits['visit_end_date'] = pd.to_datetime(all_visits['visit_end_date'])\n",
    "all_visits = all_visits.loc[(all_visits['cohort_start_date']-all_visits['visit_end_date']).dt.days >= num_days_prediction]\n",
    "all_visits = all_visits.loc[(all_visits['cohort_start_date']-all_visits['visit_start_date']).dt.days <= 2555]\n",
    "all_visits['days_to_cohort_start'] = (all_visits['cohort_start_date']-all_visits['visit_start_date']).dt.days\n",
    "\n",
    "all_conds = pd.read_csv('psychosis_prediction/temporal_conditions.csv')\n",
    "all_conds = all_conds.loc[all_conds['person_id'].isin(df_pop['person_id'])]\n",
    "all_conds['cohort_start_date'] = pd.to_datetime(all_conds['cohort_start_date'])\n",
    "all_conds['condition_start_date'] = pd.to_datetime(all_conds['condition_start_date'])\n",
    "all_conds['days_to_cohort_start'] = (all_conds['cohort_start_date']-all_conds['condition_start_date']).dt.days\n",
    "all_conds = all_conds.loc[all_conds['days_to_cohort_start'] >= num_days_prediction]\n",
    "all_conds = all_conds.loc[all_conds['days_to_cohort_start'] <= 2555]\n",
    "\n",
    "all_procedures = pd.read_csv('psychosis_prediction/temporal_procedures.csv')\n",
    "all_procedures = all_procedures.loc[all_procedures['person_id'].isin(df_pop['person_id'])]\n",
    "all_procedures['cohort_start_date'] = pd.to_datetime(all_procedures['cohort_start_date'])\n",
    "all_procedures['procedure_date'] = pd.to_datetime(all_procedures['procedure_date'])\n",
    "all_procedures['days_to_cohort_start'] = (all_procedures['cohort_start_date']-all_procedures['procedure_date']).dt.days\n",
    "all_procedures = all_procedures.loc[all_procedures['days_to_cohort_start'] >= num_days_prediction]\n",
    "all_procedures = all_procedures.loc[all_procedures['days_to_cohort_start'] <= 2555]\n",
    "\n",
    "all_labs = pd.read_csv('psychosis_prediction/temporal_labs.csv')\n",
    "all_labs = all_labs.loc[all_labs['person_id'].isin(df_pop['person_id'])]\n",
    "all_labs['cohort_start_date'] = pd.to_datetime(all_labs['cohort_start_date'])\n",
    "all_labs['measurement_date'] = pd.to_datetime(all_labs['measurement_date'])\n",
    "all_labs['days_to_cohort_start'] = (all_labs['cohort_start_date']-all_labs['measurement_date']).dt.days\n",
    "all_labs = all_labs.loc[all_labs['days_to_cohort_start'] >= num_days_prediction]\n",
    "all_labs = all_labs.loc[all_labs['days_to_cohort_start'] <= 2555]\n",
    "\n",
    "all_meds = pd.read_csv('psychosis_prediction/temporal_medications.csv')\n",
    "all_meds = all_meds.loc[all_meds['person_id'].isin(df_pop['person_id'])]\n",
    "all_meds['cohort_start_date'] = pd.to_datetime(all_meds['cohort_start_date'])\n",
    "all_meds['drug_era_start_date'] = pd.to_datetime(all_meds['drug_era_start_date'])\n",
    "all_meds['drug_era_end_date'] = pd.to_datetime(all_meds['drug_era_end_date'])\n",
    "all_meds = all_meds.loc[(all_meds['cohort_start_date']-all_meds['drug_era_end_date']).dt.days >= num_days_prediction]\n",
    "all_meds = all_meds.loc[(all_meds['cohort_start_date']-all_meds['drug_era_start_date']).dt.days <= 2555]\n",
    "all_meds['days_to_cohort_start'] = (all_meds['cohort_start_date']-all_meds['drug_era_start_date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9eb84",
   "metadata": {},
   "source": [
    "### Process each dataframe so that they are easier to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94007926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_events(df, threshold=0.01):\n",
    "    \"\"\"\n",
    "    This function takes in a dataframe with columns \"person_id\" and \"concept_id\". It counts \n",
    "    the number of unique patients for whom each concept exists and limits the dataframe to \n",
    "    concepts that exist in at least [threshold] fraction of patients\n",
    "    \"\"\"\n",
    "    remove_rare_events = df[['person_id', 'concept_id']].drop_duplicates().value_counts('concept_id')\n",
    "    keep_events = list(remove_rare_events[remove_rare_events > threshold*len(df['person_id'].unique())].index)\n",
    "    df = df.loc[df['concept_id'].isin(keep_events)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7210a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the names of the columns to make next concatenation easier\n",
    "all_procedures = all_procedures[['person_id', 'days_to_cohort_start', 'procedure_concept_id']].drop_duplicates()\n",
    "all_procedures.rename({'procedure_concept_id':'concept_id'}, axis=1, inplace=True)\n",
    "all_procedures = remove_rare_events(all_procedures)\n",
    "\n",
    "all_labs = all_labs[['person_id', 'days_to_cohort_start', 'measurement_concept_id']].drop_duplicates()\n",
    "all_labs.rename({'measurement_concept_id':'concept_id'}, axis=1, inplace=True)\n",
    "all_labs = remove_rare_events(all_labs)\n",
    "\n",
    "all_conds = all_conds[['person_id', 'condition_concept_id', 'days_to_cohort_start']].drop_duplicates()\n",
    "all_conds.rename({'condition_concept_id':'concept_id'}, axis=1, inplace=True)\n",
    "all_conds = remove_rare_events(all_conds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712b5d4",
   "metadata": {},
   "source": [
    "For medications, extend the dataframe so the person has one entry for each day they are on that medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6896146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_399374/1264632904.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_meds['days_exposed'] = (all_meds['drug_era_end_date']-all_meds['drug_era_start_date']).dt.days\n"
     ]
    }
   ],
   "source": [
    "all_meds['days_exposed'] = (all_meds['drug_era_end_date']-all_meds['drug_era_start_date']).dt.days\n",
    "all_meds = all_meds[['person_id', 'days_exposed','drug_concept_id', 'days_to_cohort_start']].drop_duplicates()\n",
    "# change the name to make merging the dfs easier later\n",
    "all_meds.rename({'drug_concept_id':'concept_id'}, axis=1, inplace=True)\n",
    "\n",
    "all_meds = remove_rare_events(all_meds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91c1038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685330\n",
      "24370\n",
      "597768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 597768/597768 [01:16<00:00, 7792.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37340285"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(all_meds))\n",
    "single_day_meds = all_meds.loc[all_meds['days_exposed']==1]\n",
    "multi_day_meds = all_meds.loc[all_meds['days_exposed']>1]\n",
    "list_temp_arrs = []\n",
    "for i in tqdm(range(0,len(multi_day_meds))):\n",
    "    n_repeats = multi_day_meds.iloc[i]['days_exposed']\n",
    "    temp_arr = multi_day_meds.iloc[i].values.reshape(-1, 1).repeat(n_repeats, axis=0).reshape(4,n_repeats).T\n",
    "    replace_days_to_cohort_start = np.arange(multi_day_meds.iloc[i]['days_to_cohort_start'], multi_day_meds.iloc[i]['days_to_cohort_start']-n_repeats, -1)\n",
    "    temp_arr[:,-1] = replace_days_to_cohort_start\n",
    "    list_temp_arrs.append(temp_arr)\n",
    "    \n",
    "multi_day_meds = pd.DataFrame(np.vstack(list_temp_arrs), columns = single_day_meds.columns)\n",
    "all_meds = pd.concat([multi_day_meds, single_day_meds])\n",
    "\n",
    "all_meds.drop(['days_exposed'], axis=1, inplace=True)\n",
    "len(all_meds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269db57f",
   "metadata": {},
   "source": [
    "For visits (specifically inpatient and ED), create a new dataframe (los_df) where each \"overnight\" that they are on this visit is a separate entry. Then, we can change the feature numbers (9204 and 9207) and treat this as a separate feature from number of visits of each type. los_df will also be concatenated along with all_visits, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "363f8d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 31691/31691 [00:04<00:00, 7761.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252561"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_visits['los'] = (all_visits['visit_end_date']-all_visits['visit_start_date']).dt.days\n",
    "los_df = all_visits.loc[all_visits['visit_concept_id'].isin([9201, 9203])]\n",
    "los_df = los_df.loc[los_df['los']>0]\n",
    "los_df = los_df[['person_id', 'visit_concept_id', 'los', 'days_to_cohort_start']]\n",
    "\n",
    "list_temp_arrs = []\n",
    "for i in tqdm(range(0,len(los_df))):\n",
    "    n_repeats = los_df.iloc[i]['los']\n",
    "    temp_arr = los_df.iloc[i].values.reshape(-1, 1).repeat(n_repeats, axis=0).reshape(4,n_repeats).T\n",
    "    replace_days_to_cohort_start = np.arange(los_df.iloc[i]['days_to_cohort_start'], los_df.iloc[i]['days_to_cohort_start']-n_repeats, -1)\n",
    "    temp_arr[:,-1] = replace_days_to_cohort_start\n",
    "    list_temp_arrs.append(temp_arr)\n",
    "\n",
    "los_df = pd.DataFrame(np.vstack(list_temp_arrs), columns = ['person_id', 'concept_id', 'los', 'days_to_cohort_start'])\n",
    "los_df['concept_id'].replace({9201:9205, 9203:9207}, inplace=True)\n",
    "los_df.drop(['los'], axis=1, inplace=True)\n",
    "len(los_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb31bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visits = all_visits[['person_id', 'days_to_cohort_start', 'visit_concept_id']].drop_duplicates()\n",
    "all_visits.rename({'visit_concept_id':'concept_id'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7fc74",
   "metadata": {},
   "source": [
    "### Concatenate all these dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09b1d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat([all_conds, all_meds, los_df, all_visits, all_labs, all_procedures])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f565c",
   "metadata": {},
   "source": [
    "### Rather than day-by-day, group the days into chunks of size time_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a40538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_chunk = 90\n",
    "all_features['days_to_cohort_start'] = all_features['days_to_cohort_start']//time_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e5065e",
   "metadata": {},
   "source": [
    "## Create sparse dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "feea9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpr_row = all_features.groupby(['person_id', 'days_to_cohort_start']).grouper\n",
    "idx_row = grpr_row.group_info[0]\n",
    "\n",
    "grpr_col = all_features.groupby('concept_id').grouper\n",
    "idx_col = grpr_col.group_info[0]\n",
    "\n",
    "sparse_data = csr_matrix((all_features['concept_id'].values, (idx_row, idx_col)),shape=(grpr_row.ngroups, grpr_col.ngroups))\n",
    "\n",
    "df_index = grpr_row.result_index\n",
    "df_columns = list(grpr_col.result_index)\n",
    "sparse_df = pd.DataFrame.sparse.from_spmatrix(sparse_data, index = df_index, columns = df_columns)\n",
    "\n",
    "\"\"\"\n",
    "The above code is summing the concept_id within each time chunk. \n",
    "Therefore, if I divide by the concept id (which is the column name), I will get the number of \n",
    "times this occurs in each cohort\n",
    "\"\"\"\n",
    "for i in sparse_df.columns:\n",
    "    sparse_df[i] = sparse_df[i]/i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c443dc0",
   "metadata": {},
   "source": [
    "Right now, the sparse index does not have the same number of time chunks per person -- it only has time chunks where there is a feature present. Next, I want to change the sparse_df to a regular dataframe (also so I can do scaling) where the index is 1. person_id; 2. time_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003a7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10d79c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe where each of the people/times I want exist\n",
    "index_patients = sparse_df.index.get_level_values(0).unique()\n",
    "patient_indices = np.arange(0,len(index_patients), 1)\n",
    "\n",
    "time_chunks = np.arange(1, all_features['days_to_cohort_start'].max()+1, 1)\n",
    "feature_indices = np.arange(0, sparse_df.shape[1], 1)\n",
    "\n",
    "df_features = pd.DataFrame(data = 0, index = pd.MultiIndex.from_product([index_patients, time_chunks], names=[\"person_id\", \"time_chunk\"]), columns = sparse_df.columns, dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1608b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate df_features with the data from sparse_df\n",
    "sparse_df = sparse_df[sparse_df.index.get_level_values(1)>0]\n",
    "df_features.loc[sparse_df.index] = sparse_df.values # non-sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb1aaf",
   "metadata": {},
   "source": [
    "# Preprocessing of dataframe\n",
    "- Turn the dataframe df_features into a sparse dataframe to reduce memory\n",
    "- Create train-test split\n",
    "- Min-Max Scaling (so that I can maintain sparsity)\n",
    "- Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a57d42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataframe sparse for faster processing\n",
    "sparse_df_features = pd.DataFrame.sparse.from_spmatrix(csr_matrix(df_features.values), index = pd.MultiIndex.from_product([index_patients, time_chunks], names=[\"person_id\", \"time_chunk\"]), columns = sparse_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8584b151",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87d0d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create my y_values vector in the correct order (according to index_patients)\n",
    "mat_y = np.asarray(df_pop.set_index('person_id').loc[index_patients, 'sz_flag']).reshape(len(df_pop), 1)\n",
    "\n",
    "# get first train-test split (to get test test data)\n",
    "train_pop, test_pop, train_labels, test_labels, train_inds, test_inds = train_test_split(df_pop, mat_y, np.arange(0, len(df_pop), 1), random_state=23, test_size=0.2, stratify=mat_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "941d1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training/testing feature sets\n",
    "train_sparse_mat = sparse_df_features.loc[train_pop['person_id']].values\n",
    "test_sparse_mat = sparse_df_features.loc[test_pop['person_id']].values\n",
    "\n",
    "# create training/testing labels\n",
    "y_train = mat_y[train_inds]\n",
    "y_test = mat_y[test_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b978c4",
   "metadata": {},
   "source": [
    "### Min-Max Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36fa1279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with fit/first transform\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_sparse_mat = scaler.fit_transform(train_sparse_mat)\n",
    "print('done with fit/first transform')\n",
    "test_sparse_mat = scaler.transform(test_sparse_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035a3e3",
   "metadata": {},
   "source": [
    "### Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16346f17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_sparse_mat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_690044/1617695511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'psychosis_prediction/90days_balanced_features_labels.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sparse_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sparse_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_sparse_mat' is not defined"
     ]
    }
   ],
   "source": [
    "np.savez('psychosis_prediction/90days_balanced_features_labels.npz', train_sparse_mat, test_sparse_mat, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9bbb24",
   "metadata": {},
   "source": [
    "# Use preprocessed data to create the data loader objects\n",
    "- Load in data\n",
    "- Create train/validation split from X_train, y_train (stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae82602",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mats = np.load('psychosis_prediction/90days_balanced_features_labels.npz')\n",
    "X_trainval, X_test, y_trainval, y_test = loaded_mats['arr_0'], loaded_mats['arr_1'], loaded_mats['arr_2'], loaded_mats['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3976f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gves us the training/validation indices; then when we make the data 3d we can \n",
    "# get X_train and X_val\n",
    "train_inds, val_inds, train_labels, test_labels = train_test_split(np.arange(0, len(y_trainval), 1), y_trainval, random_state=24, test_size=0.1, stratify=y_trainval)\n",
    "\n",
    "y_val = y_trainval[val_inds]\n",
    "y_train = y_trainval[train_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9dd96c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1901, 2089, 28)\n",
      "(6842, 2089, 28)\n",
      "(761, 2089, 28)\n"
     ]
    }
   ],
   "source": [
    "# transform the data into a 3-dimensional matrix\n",
    "# person_id x features x sequence\n",
    "num_train_pop = len(y_train)\n",
    "num_test_pop = len(y_test)\n",
    "num_val_pop = len(y_val)\n",
    "len_sequence = int(X_trainval.shape[0]/len(y_trainval))\n",
    "\n",
    "num_features = X_trainval.shape[1]\n",
    "test_mat_features = X_test.reshape(num_test_pop, len_sequence, num_features).transpose(0, 2, 1)\n",
    "print(test_mat_features.shape)\n",
    "\n",
    "trainval_mat_features = X_trainval.reshape(num_train_pop+num_val_pop, len_sequence, num_features).transpose(0, 2, 1)\n",
    "train_mat_features = trainval_mat_features[train_inds,:,:]\n",
    "print(train_mat_features.shape)\n",
    "val_mat_features = trainval_mat_features[val_inds,:,:]\n",
    "print(val_mat_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3acf8dc",
   "metadata": {},
   "source": [
    "### Create dataloader objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "932b83da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "863c4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.TensorDataset(torch.Tensor(train_mat_features), torch.Tensor(y_train))\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cf5f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = torch.utils.data.TensorDataset(torch.Tensor(val_mat_features), torch.Tensor(y_val))\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9d00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.utils.data.TensorDataset(torch.Tensor(test_mat_features), torch.Tensor(y_test))\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3d38d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'psychosis_prediction/train_loader.pth'\n",
    "path_val = 'psychosis_prediction/train_loader.pth'\n",
    "path_test = 'psychosis_prediction/train_loader.pth'\n",
    "\n",
    "torch.save(train_loader, path_train)\n",
    "torch.save(val_loader, path_val)\n",
    "torch.save(test_loader, path_test)\n",
    "\n",
    "device = torch.device(\"cuda:0\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd59feb",
   "metadata": {},
   "source": [
    "# Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "accd7eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, feature_size):\n",
    "        super(AttentionModel, self).__init__()\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.hidden_size = hidden_size\n",
    "        self.feature_size = feature_size\n",
    "        # self.W_s1 = nn.Linear(hidden_size, 350)\n",
    "        # self.W_s2 = nn.Linear(350, 30)\n",
    "        self.W_s1 = nn.Linear(hidden_size, 1)\n",
    "        # self.fc_layer = nn.Linear(30 * hidden_size, 2000)\n",
    "        self.rnn = nn.GRU(self.feature_size, self.hidden_size, bidirectional=False)\n",
    "        self.regressor = nn.Sequential(nn.BatchNorm1d(num_features=hidden_size),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.Dropout(0.4),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.Linear(hidden_size, 1),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.Sigmoid())\n",
    "\n",
    "    def attention_net(self, lstm_output):\n",
    "        attn_weight_vector = F.tanh(self.W_s1(lstm_output))\n",
    "        attn_weight_vector = torch.nn.Softmax(dim=1)(attn_weight_vector)\n",
    "        scaled_latent = lstm_output*attn_weight_vector\n",
    "        return torch.sum(scaled_latent, dim=1), attn_weight_vector\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.to(self.device)\n",
    "        batch_size = input.shape[0]\n",
    "        input = input.permute(2, 0, 1) # Input to GRU should be (seq_len, batch, input_size)\n",
    "        h_0 = Variable(torch.zeros(1, batch_size, self.hidden_size)).to(self.device) #(num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "        output, final_hidden_state = self.rnn(input, h_0)   # output.size() =  (seq_len, batch, hidden_size)\n",
    "                                                            # final_hidden_state.size() = (1, batch, hidden_size)\n",
    "        output = output.permute(1, 0, 2)  # output.size() = (batch, seq_len, hidden_size)\n",
    "\n",
    "        concept_vector, attn_weights = self.attention_net(output)\n",
    "        # attn_weight_matrix.size() = (batch_size, num_seq)\n",
    "        #hidden_matrix = torch.bmm(attn_weight_matrix, output)   # hidden_matrix.size() = (batch_size, r, hidden_size)\n",
    "        #fc_out = self.fc_layer(hidden_matrix.view(-1, hidden_matrix.size()[1] * hidden_matrix.size()[2]))\n",
    "        p = self.regressor(concept_vector)\n",
    "        return p\n",
    "\n",
    "    def get_attention_weights(self, input):\n",
    "        input = input.to(self.device)\n",
    "        batch_size = input.shape[0]\n",
    "        input = input.permute(2, 0, 1) # Input to GRU should be (seq_len, batch, input_size)\n",
    "        h_0 = Variable(torch.zeros(1, batch_size, self.hidden_size)).to(self.device) #(num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "        output, final_hidden_state = self.rnn(input, h_0)   # output.size() =  (seq_len, batch, hidden_size)\n",
    "                                                            # final_hidden_state.size() = (1, batch, hidden_size)\n",
    "        output = output.permute(1, 0, 2)  # output.size() = (batch, seq_len, hidden_size)\n",
    "\n",
    "        _, attn_weights = self.attention_net(output)\n",
    "        return attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25f234",
   "metadata": {},
   "source": [
    "# LSTM from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "296ad381",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, feature_size, seq_len):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.hidden_size = hidden_size\n",
    "        self.feature_size = feature_size\n",
    "        self.W_s1 = nn.Linear(hidden_size, 1)\n",
    "        self.seq_len = seq_len\n",
    "        # self.fc_layer = nn.Linear(30 * hidden_size, 2000)\n",
    "        self.rnn = nn.GRU(self.feature_size, self.hidden_size, num_layers = 4, bidirectional=False)\n",
    "        self.regressor = nn.Sequential(nn.Linear(self.hidden_size*self.seq_len, 150),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.Dropout(0.2),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.Linear(150,1),\n",
    "                                       nn.LeakyReLU(),\n",
    "                                       nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = X.to(self.device)\n",
    "        batch_size = X.shape[0]\n",
    "        X = X.permute(2, 0, 1) # Input to GRU should be (seq_len, batch, input_size)\n",
    "        h_0 = Variable(torch.rand(4, batch_size, self.hidden_size)).to(self.device) #(num_layers * num_directions, batch, hidden_size)\n",
    "        h_0 = h_0*2-1\n",
    "        \n",
    "        output, final_hidden_state = self.rnn(X, h_0)   # output.size() =  (seq_len, batch, hidden_size)\n",
    "                                                            # final_hidden_state.size() = (1, batch, hidden_size)\n",
    "        output = output.permute(1, 0, 2)  # output.size() = (batch, seq_len, hidden_size)\n",
    "\n",
    "        output = output.reshape((output.shape[0], output.shape[1]*output.shape[2]))\n",
    "        \n",
    "        p = self.regressor(output)\n",
    "        return p\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ca2a4",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3d6d8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") \n",
    "loss_weights = torch.tensor(sum(y_train==0)/sum(y_train)).to(device)\n",
    "def train(train_loader, model, device, optimizer, loss_criterion=torch.nn.BCEWithLogitsLoss(pos_weight = loss_weights)):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    auc_train = 0\n",
    "    epoch_loss = 0\n",
    "    list_training_loss = []\n",
    "    true_ys = []\n",
    "    pred_ys = []\n",
    "    for i, (signals, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        signals, labels = torch.Tensor(signals.float()).to(device), torch.Tensor(labels.float()).to(device)\n",
    "        #labels = labels.view(labels.shape[0], )\n",
    "        logits = model(signals) #probability of one of the outputs\n",
    "        true_ys.append(labels.detach().cpu().numpy())\n",
    "        pred_ys.append(logits.detach().cpu().numpy())\n",
    "\n",
    "        loss = loss_criterion(logits, labels)\n",
    "        epoch_loss = + loss.item()\n",
    "        list_training_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    true_ys_flattened = np.concatenate(true_ys).ravel()\n",
    "    pred_ys_flattened = np.concatenate(pred_ys).ravel()\n",
    "    pred_labels = (pred_ys_flattened>0.5)*1\n",
    "    \n",
    "    auc_train = roc_auc_score(true_ys_flattened, pred_ys_flattened)\n",
    "    auprc_train = average_precision_score(true_ys_flattened, pred_ys_flattened)\n",
    "    correct_label = accuracy_score(true_ys_flattened, pred_labels)\n",
    "    #precision_train = precision_score(true_ys_flattened, pred_labels)\n",
    "    precision_train = 'change'\n",
    "    recall_train = recall_score(true_ys_flattened, pred_labels)\n",
    "\n",
    "    return recall_train, precision_train, auc_train,auprc_train, correct_label, np.mean(list_training_loss), i + 1\n",
    "\n",
    "def test(test_loader, model, device, criteria=torch.nn.BCEWithLogitsLoss(pos_weight = loss_weights), verbose=True):\n",
    "    model.to(device)\n",
    "    correct_label = 0\n",
    "    count = 0\n",
    "    loss = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    list_testing_loss = []\n",
    "    true_ys = []\n",
    "    pred_ys = []\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        x, y = torch.Tensor(x.float()).to(device), torch.Tensor(y.float()).to(device)\n",
    "        out = model(x)\n",
    "        #y = y.view(y.shape[0], )\n",
    "        \n",
    "        pred_labels = (out > 0.5)*1\n",
    "        true_ys.append(y.detach().cpu().numpy())\n",
    "        pred_ys.append(out.detach().cpu().numpy())\n",
    "\n",
    "        count = + 1\n",
    "        loss += criteria(out, y).item()\n",
    "        list_testing_loss.append(criteria(out, y).item())\n",
    "        total += len(x)\n",
    "    \n",
    "    true_ys_flattened = np.concatenate(true_ys).ravel()\n",
    "    pred_ys_flattened = np.concatenate(pred_ys).ravel()\n",
    "    pred_labels = (pred_ys_flattened>0.5)*1\n",
    "    print(sum(pred_labels))\n",
    "    auc_test = roc_auc_score(true_ys_flattened, pred_ys_flattened)\n",
    "    auprc_test = average_precision_score(true_ys_flattened, pred_ys_flattened)\n",
    "    recall_test = recall_score(true_ys_flattened, pred_labels)\n",
    "    correct_label = accuracy_score(true_ys_flattened, pred_labels)\n",
    "    #precision_test = precision_score(true_ys_flattened, pred_labels)\n",
    "    precision_test = 'change'\n",
    "\n",
    "    return recall_test, precision_test, auc_test, auprc_test, correct_label, np.mean(list_testing_loss)\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, optimizer, n_epochs, device ,cv=0):\n",
    "    train_loss_trend = []\n",
    "    test_loss_trend = []\n",
    "\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        recall_train, precision_train, auc_train, auprc_train, correct_label_train, epoch_loss, n_batches = train(train_loader,\n",
    "                                                                                                     model,\n",
    "                                                                                                     device, optimizer)\n",
    "        recall_test, precision_test, auc_test, auprc_test, correct_label_test, test_loss = test(valid_loader, model,\n",
    "                                                                                    device)\n",
    "        train_loss_trend.append(epoch_loss)\n",
    "        test_loss_trend.append(test_loss)\n",
    "        lr_scheduler.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print('\\nEpoch %d' % (epoch))\n",
    "            print('Training ===>loss: ', epoch_loss,\n",
    "                  ' Accuracy: %.2f percent' % (100*correct_label_train),\n",
    "                  ' AUC: %.2f' % (auc_train),\n",
    "                 ' AUPRC: %.2f' % (auprc_train))\n",
    "            print('Test ===>loss: ', test_loss,\n",
    "                  ' Accuracy: %.2f percent' % (100*correct_label_test),\n",
    "                  ' AUC: %.2f' % (auc_test),\n",
    "                 ' AUPRC: %.2f' % (auprc_test))\n",
    "        \"\"\"\n",
    "        if epoch > 10:\n",
    "            if test_loss_trend[-2] < test_loss_trend[-1]:\n",
    "                print('Breaking at epoch', epoch)\n",
    "                break\n",
    "        \"\"\"\n",
    "\n",
    "    # Save model and results\n",
    "    \"\"\"\n",
    "    if not os.path.exists(os.path.join(\"./ckpt/\", data)):\n",
    "        os.mkdir(os.path.join(\"./ckpt/\", data))\n",
    "    if not os.path.exists(os.path.join(\"./plots/\", data)):\n",
    "        os.mkdir(os.path.join(\"./plots/\", data))\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), 'psychosis_prediction/models/new_features_model1.pt')\n",
    "    plt.plot(train_loss_trend, label='Train loss')\n",
    "    plt.plot(test_loss_trend, label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('psychosis_prediction/models/new_features_model1_loss.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b215ed06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline AUPRC: [0.1870798]\n",
      "20\n",
      "\n",
      "Epoch 0\n",
      "Training ===>loss:  1.1825622916221619  Accuracy: 59.09 percent  AUC: 0.55  AUPRC: 0.20\n",
      "Test ===>loss:  1.1716631650924683  Accuracy: 79.50 percent  AUC: 0.56  AUPRC: 0.20\n",
      "6\n",
      "2\n",
      "6\n",
      "1\n",
      "48\n",
      "77\n",
      "83\n",
      "226\n",
      "160\n",
      "233\n",
      "\n",
      "Epoch 10\n",
      "Training ===>loss:  1.1667788624763489  Accuracy: 71.54 percent  AUC: 0.65  AUPRC: 0.39\n",
      "Test ===>loss:  1.1780044436454773  Accuracy: 61.76 percent  AUC: 0.54  AUPRC: 0.21\n",
      "221\n",
      "180\n",
      "220\n",
      "271\n",
      "207\n",
      "258\n",
      "305\n",
      "209\n",
      "270\n",
      "248\n",
      "\n",
      "Epoch 20\n",
      "Training ===>loss:  1.1553741991519928  Accuracy: 71.88 percent  AUC: 0.72  AUPRC: 0.56\n",
      "Test ===>loss:  1.181088149547577  Accuracy: 62.42 percent  AUC: 0.54  AUPRC: 0.20\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('baseline AUPRC:',sum(y_train)/len(y_train))\n",
    "\n",
    "#train_loader = torch.load('psychosis_prediction/train_loader.pth')\n",
    "#val_loader = torch.load('psychosis_prediction/val_loader.pth')\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size=batchsize\n",
    "feature_size = train_mat_features.shape[1]\n",
    "\n",
    "#for train_loader, val_loader in zip()\n",
    "model = AttentionModel(hidden_size = 250, feature_size = feature_size)\n",
    "#model = RNNModel(hidden_size = 6, feature_size = feature_size, seq_len = train_mat_features.shape[2])\n",
    "parameters = model.parameters()\n",
    "optimizer = torch.optim.Adam(parameters, lr=1e-3, weight_decay=0.01)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.9)\n",
    "\n",
    "\n",
    "train_model(model, train_loader, val_loader, optimizer, n_epochs, device ,cv=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f11f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
